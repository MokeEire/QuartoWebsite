---
title: "Parsing XML with R"
subtitle: "Untangling congressional legislative data"
date: "2022-07-14"
categories: 
  - data
  - governance
  - R
format: 
  html: 
    toc: true
    code-link: true
    code-fold: show
    code-tools: true
    comments:
      hypothesis: true
---

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false
library(extrafont)
library(reactable)

source("https://github.com/MokeEire/my-reps/raw/master/R/parsing_functions.R")
bill_xml_url = "https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml"
bill_xml_file = read_xml(bill_xml_url)

```

Unlike Excel spreadsheets, CSV files, and other tabular formats, (e)Xtensible Markup Language (XML) is a storage format designed to contain any "arbitrary" structure[^1] of data. XML's flexibility is useful for storing information like financial transactions and recipes to webpage content and document formatting[^2]. If you have worked with XML before, you'll know it can be a bit of a pain to transform into a tabular format typically used in data analysis. The good news is you're not alone! This article will help you to load XML files with R, extract what you need from them, and store the results in a analysis-friendly data frame.

[^1]: [Wikipedia](https://en.wikipedia.org/wiki/XML) for the curious. Don't miss the drama about Microsoft's "vociferous protests" as one of the co-editors started working with Netscape.

[^2]: The *x* at the end of Microsoft file types (e.g. .docx, .xlsx, .pptx) stands for XML.

::: {.callout-tip appearance="simple"}
## What you'll learn:

-   Load and parse XML files in R using the `{XML}` and `{xml2}` packages

-   Explore the structure of XML documents

-   List, map, and flatten your data into a tabular format using `{purrr}`, and making use of `{tidyr}`'s list columns when necessary
:::

# What is XML?

At its core, XML is "information wrapped in tags". Think of XML's structure as branches of a tree, with each branch having their own leaves. Below is an example of a bookstore's data in XML format from [w3schools](https://www.w3schools.com/XML/xml_usedfor.asp).

``` xml
<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>
```

Takeaways:

1.  `<bookstore>` is the parent, or *root* element
2.  The book store has two `<book>` child elements
3.  Each book element contains their own child elements which are individual data points about each book

::: {.callout-note appearance="simple"}
## Note

Attributes are denoted by key/value assignment in a tag. In the example above, the book's category is stored as an attribute. Attributes are a useful way to store data related to a specific element for HTML, but using child elements is typically preferred in XML[^3]. However, you'll still likely run into data stored in attributes so we'll touch on extracting data from both.
:::

[^3]: To learn more about what XML is and how to use it, I recommend going through [w3school's XML tutorial](https://www.w3schools.com/XML/default.asp).

# Navigating XML with R

I'll be using congressional bill data from the [United States Government Publishing Office (GPO)](https://www.gpo.gov/) to illustrate potential complexities of XML structures. You can follow along by downloading the sample bill[^4] [here](https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml "HR-391: Global Health Security Act of 2021").

[^4]: I chose the bill [*HR-391: Global Health Security Act of 2021*](https://www.govinfo.gov/app/details/BILLS-117hr391rfs)only because it contains good examples of the challenges of parsing XML data, so consider this a standard *retweets â‰  endorsements* situation*.*

I'll be using four very helpful R packages throughout this post:

-   `{XML}` and `{xml2}` provide functions for reading in and parsing XML[^5]

-   `{purrr}` and `{tidyr}` (loaded as part of the `{tidyverse}` package) help us wrangle lists and transform XML to data frames.

[^5]: Between `{XML}` and `{xml2}` there are numerous ways to load XML data with R. I generally prefer `{xml2}` but I suggest looking through the packages' documentation to find the right function for your task

To read in the file, you can pass the URL or file path of the XML file to `read_xml()` , which returns an `xml_document` object[^6].

[^6]: `xml_document` is one of the "key classes" used in the `{xml2}` library, the others being `xml_node` (a single node), and `xml_nodeset` (a set of nodes).

```{r}
#| label: read-xml
#| code-fold: show
#| code-summary: "Load and view XML file"

# copy the comment below to install the packages
# install.packages(c("tidyverse", "XML", "xml2))
library(tidyverse)
library(XML)
library(xml2)

# Read XML file
bill_xml = read_xml("https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml")

# Look at xml_document's contents
xml_contents(bill_xml)
```

The top-level nodes are `<bill>` and `<dublinCore>`[^7]. The latter is a metadata identifier and doesn't contain bill-related information, so we can use `xml_child()` to select just data inside the `<bill>` node.

[^7]: Which is a document metadata identifier, not an Irish metal music genre. While very useful in its own right, it isn't relevant for our task here.

```{r}
#| code-fold: show
#| label: xml-bill-child
#| code-overflow: wrap
# Return child nodes named bill
(bill_node = xml_child(bill_xml, "bill"))
```

So now we have all the bill data in one place. How do we get it into a data frame?

# Define the output

Before we start transforming the data, it's important to think about what kind of data frame you want to produce. This will determine how the data is manipulated and depending on the structure of your XML data, there can be a lot of different options.

The importance of understanding the structure of your data brings us to one of the cardinal rules of data analysis:

::: callout-tip
## Look at your data

In fact, you could even say *stare* at it. Understanding the structure and contents of your data is essential for designing a solution to consistently process the data.
:::

I want to create a data frame of congressional bills where each bill forms a single row. Elements which have **only one value** (i.e. *singular*) like `billNumber`, `createDate`, and `billType` are straightforward, but there are also *nested* elements like `recordedVotes`, `committees`, and `actions` which each have multiple data points. In some cases you may want to store multiple attributes in a *wide* format e.g. storing committees as `committee_1`, `committee_2`, etc. I will be storing each nested element in a *long* format, meaning one row per vote, committee, and action.

In order to construct both a bill-level data frame and retain nested elements, we'll be taking advantage of `{tidyr}`'s `nest()` function, which nests data inside [list columns](https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html). Columns in a data frame are typically *atomic vectors*[^8] of equal length, but list columns enable us to store data of varying length and type, including data frames themselves. The end result will look like this:

[^8]: Atomic vectors are vectors with elements of the same type (e.g. numeric, character, etc.) as opposed to *general vectors*, or lists, which can contain a variety of types.

```{r}
#| label: example-bill
#| echo: false
#| message: false
#| column: page

library(knitr)
(example_bill_df = extract_bill_status(bill_xml_link, log_types = NULL)) %>% 
  kable()

# glimpse(example_bill_df)
```

```{r}
#| label: example-bill-rt
#| echo: false
#| eval: true
#| column: page
example_bill_df %>% #glimpse() # here to check the data
  # select(
  #   -bill_id, -where(is_list) # remove list columns?
  # ) %>%
  reactable::reactable(
    theme = moke_rt(),
    compact = T,
    resizable = T,
    wrap = F,
    columns = list(
      "bill_number" = colDef(width = 100),
      "create_date" = colDef(format = colFormat(date = T), width = 100),
      "update_date" = colDef(format = colFormat(date = T), width = 100),
      "origin_chamber" = colDef(show=F),
      "bill_type" = colDef(width = 80),
      "introduced_date" = colDef(format = colFormat(date = T), width = 130),
      "congress" = colDef(width = 80),
      "constitutional_authority_statement_text" = colDef(show=F),
      "title" = colDef(minWidth = 180),
      "version" = colDef(show = F, width = 80),
      "policy_areas" = colDef(width = 120),
      "legislative_subjects" = colDef(width = 200),
      "bill_summaries" = colDef(show=F),
      "bill_titles" = colDef(show=F),
      "bill_text_versions" = colDef(show=F),
      "latest_action_action_date" = colDef(name = "action_date", 
                                           width = 110,
                                           format = colFormat(date = T)),
      "latest_action_text" = colDef(name = "action_text",
                                    minWidth = 200),
      "committees" = colDef(minWidth = 80),
      "votes" = colDef(width = 80),
      "actions" = colDef(width = 80),
      "action_counts" = colDef(show=F),
      "sponsors" = colDef(width = 80),
      "cosponsors" = colDef(width = 80)
    ), 
    columnGroups = list(
      colGroup(name = "Latest Action",
                            columns = c("latest_action_action_date",
                                        "latest_action_text")),
      colGroup(name = "Nested Data",
                            columns = c("committees", "votes", "actions", 
                                        "sponsors", "cosponsors"))
    )
  )
```

Here's a `glimpse()` of some of the nested data:

::: panel-tabset
## Committees

```{r}
#| label: glimpse-committees
#| echo: false
glimpse(example_bill_df[["committees"]])

```

## Votes

```{r}
#| label: glimpse-votes
#| echo: false
glimpse(example_bill_df[["votes"]])

```

## Actions

```{r}
#| label: glimpse-actio
#| echo: false
glimpse(example_bill_df[["actions"]])
```

## Sponsors

```{r}
#| label: glimpse-sponsors
#| echo: false
glimpse(example_bill_df[["sponsors"]])
```
:::

# Parsing

Okay now you should have an idea of what *your data* *is*, and what *you* *want your data to be*.

With an understanding of your data's structure and your intended output, let's break down the process into extracting 1) singular elements i.e. only one value, and 2) nested elements. Your output should inform what you do with both, but for either case I convert XML to a list and use `{purrr}` to flatten and transform the list into a data frame.

::: callout-tip
## Write Functions

If you find yourself doing similar transformations in multiple cases or copy-pasting some piece of code more than once, I would implore you to write functions because they:

1.  make your code more reliable
2.  make you think critically about how you're modifying the data
3.  are easier to debug

A good resource to start learning about writing functions is [How to Write a Function in R](https://www.earthdatascience.org/courses/earth-analytics/automate-science-workflows/write-function-r-programming/).
:::

## Singular elements

You can think of singular elements as the contents of a single cell in a data frame. In the bookstore example, you could arrange each book as a row and each child node as a column.

```{r}
bookstore_xml_text = '<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>'

bookstore_xml_parsed = xmlParse(bookstore_xml_text)

(bookstore_xml_df = xmlToDataFrame(bookstore_xml_parsed))
```

In cases where your data are entirely singular nodes, you can convert XML to a dataframe using two functions from `{XML}`[^9]: `xmlParse()` and `xmlToDataFrame()`. Because the congressional data has singular and nested element structures, the nested data in fields like `committees`, `actions`, and `sponsors` are combined into single columns. If your data is not all singular nodes like this, you'll need to do a little bit more work to get the data into a [tidy data](https://vita.had.co.nz/papers/tidy-data.html) frame.

[^9]: When you're working with both the `{XML}` and `{xml2}` libraries, it is important to note that their functions often rely on different object types. In the case of `xmlToDataFrame()`, it does not take `{xml_document}` or `{xml_node}` objects. If you try to use them, you'll see an error like this:

    ```{r}
    #| label: xml-df-error
    #| error: true

    xmlToDataFrame(bill_xml)
    ```

```{r}
#| label: xml-to-df

# First you need to use the xmlParse function
bill_xml_parse = xmlParse(bill_xml)

xmlToDataFrame(getNodeSet(bill_xml_parse, "//bill")) %>% 
  glimpse()
```

::: callout-note
## Note

In this example, we actually need to use `getNodeSet(., [path =] "//bill")` to select only nodes in `<bill>`. If we just passed `bill_xml_parse`, we would get a dataframe with two rows because the top-level nodes are bill and the metadata identifier node `<dublinCore>`.
:::

To start building our congressional bill dataset, we need to isolate singular elements like `billNumber` and `billType` by selecting nodes which meet two criteria: 1) the node does not have any child nodes of its own, and 2) the node is not an empty string. I use to extract nodes based on an [XPath](https://www.w3schools.com/xml/xml_parser.asp) (XML Path Language) string. It returns an `{xml_nodeset}` which is then coerced to a list using `as_list()`.

As the help file for `xml_find_all()` says, "XPath is like regular expressions for trees". The expression selects the nodes which match the given path or pattern[^10]. In the code below `//bill/*` selects the child nodes in a bill. The expressions `[` within the square brackets `]` are called predicates which I use to find nodes which have no children with the XPath `count` function and nodes which are not empty strings[^11].

[^10]: [A very useful table of XPath syntax](https://www.w3schools.com/XML/xpath_syntax.asp){target="_blank"}

[^11]: In the process of writing this, I discovered that using XPath made this \~5x faster than an equivalent function in R.

    ```{r}
    #| label: singular-nodes
    #| code-fold: show
    # Function to select singular child nodes from XML node
    xml_singular_nodes = function(xml_node){
      # Return child nodes of current node
      child_nodes = xml_children(xml_node)
      # Select child nodes with 0 children
      zero_length_child_nodes = child_nodes[xml_length(child_nodes) == 0]
      
      # Keep the nodes which are not empty strings
      keep(zero_length_child_nodes, ~(xml_text(.) != ""))
    }

    ```

    ```{r}
    #| label: bench-node-selection

    # Using XPath:
    # singular_nodes1 = xml_find_all(bill_xml, 
    #                                 "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")

    # Using R function:
    # singular_nodes2 = xml_singular_nodes(bill_node)

    # Check they are the same
    # all.equal(singular_nodes1, singular_nodes2)

    # benchmark the two different ways of selecting nodes
    microbenchmark::microbenchmark(
      xml_singular_nodes = xml_singular_nodes(bill_node),
      xml_find_all = xml_find_all(bill_xml, "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")
    )
    ```

```{r}
#| label: singular-nodes-list
#| code-fold: show

singular_nodes = xml_find_all(
  bill_xml, 
  "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]"
  )

(singular_list = as_list(singular_nodes)) %>% 
  glimpse()
```

Note that we didn't retain the element names so we need to assign them ourselves. When your data is in a named list, you can flatten each element in the list into a **d**ata **f**rame **c**olumn using purrr's `flatten_dfc()` .

```{r}
#| label: singular-nodes-list-named
#| code-fold: show
singular_list_named = setNames(singular_list, 
                                xml_name(singular_nodes))

(bill_df = flatten_dfc(singular_list_named)) %>% 
  glimpse()
```

```{r}
#| label: singular-nodes-rt
#| column: page
#| echo: false
#| eval: false
reactable(bill_df,
          theme = moke_rt(),
            columns = list(
              "constitutionalAuthorityStatementText" = colDef(show=F),
              "createDate" = colDef(format = colFormat(date = T), width = 100),
              "updateDate" = colDef(format = colFormat(date = T), width = 100),
              "introducedDate" = colDef(format = colFormat(date = T), width = 120),
              "congress" = colDef(width = 90),
              "originChamber" = colDef(show=F),
              "version" = colDef(show=F, width = 80),
              "billNumber" = colDef(width = 105),
              "billType" = colDef(width = 85),
              "title" = colDef(minWidth = 180)
            ))
```

## Nested elements

Parsing XML when your data is all singular is straightforward, but often XML will use a nested data structure. In this case the congressional data, actions and votes on each bill are stored in their own container elements. We can transform the data in these containers to nested data frames and use the `nest()`/`unnest()` functionality of `{tidyr}` to change the level of observation as needed.

To create each data frame, we isolate the nodes using XPath, and use the same steps as before to convert the XML to a list and then nest them in a list column.

### Multiple children with sub-elements

Actions are stored in a container node where each `<item>` represents a congressional action taken for a bill, such as being introduced, sent to a committee, debated on the floor, etc. Just as before, we use `as_list()` to convert the `{xml_nodeset}` to a list.

```{r}
#| label: actions-list
#| code-fold: show

actions_xml = xml_find_all(bill_node, "actions/item")

actions_list = as_list(actions_xml)

# Look at first action
glimpse(actions_list[[1]], width = 50)
```

For an individual action, we have the date, a list of committees related to the action, some administrative information, the text and type of action. To deal with this, we can write a function (or set of functions) like the ones below to transform actions from a list to a data frame with their own nested elements.

```{r}
#| label: actions-functions
#| code-fold: true
#| code-summary: "View Functions"
# Helper function: flatten_dfc_rename
# flatten a list to data frame and 
# rename the columns with a given prefix
flatten_dfc_rename = function(list_to_flatten, 
                          name_prefix = "prefix"){
  rename_with(
    .data = flatten_dfc(list_to_flatten), 
    .fn = ~str_c(name_prefix, "_", .),
    # Exclude columns which already start with the prefix
    .cols = -starts_with(name_prefix)
    )
}

# Function: parse_action
# Parse actions from list to data frame
parse_action = function(action){
  action %>% 
    # Flatten + rename sourceSystem elements
    map_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten + rename committees
    map_at("committees", function(committee){
      # using map_at and map_dfr to create a data frame row for each committee
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    # Lastly, clean the names
    janitor::clean_names()
}

```

```{r}
#| label: benchmark-parse-action
#| eval: false
#| include: false
# Test modify_at vs map_at
parse_action2 = function(action){
  action %>% 
    # Flatten+rename  sourceSystem elements
    modify_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten+rename committees
    modify_at("committees", function(committee){
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    janitor::clean_names()
}

# Parse the first action
parse_action2(actions_list[[1]])

# What about speed?
microbenchmark::microbenchmark(
  parse_action = parse_action(actions_list[[1]]),
  parse_action2 = parse_action2(actions_list[[1]]), times = 1000
)
```

Using the `{purrr}` library's `map_dfr()`, we apply this function to each action and combine the results into **d**ata **f**rame **r**ows. Here's the output of this process:

```{r}
# Parse the first action
(actions_df = map_dfr(actions_list, parse_action)) %>% 
  glimpse()
```

When you plan to combine rows into a data frame or `unnest()` the data in the future, it is useful to be explicit about the expected data types of each column. This can be done using `type_convert()`. Because we are only adding a single row of data to `bill_df` we can encase the actions in a list and use dollar assignment. If you were adding multiple rows of data, you would need to make sure that you are adding a column of the same length as `bill_df`.

```{r}
#| label: actions-dfr
#| code-fold: show

# Specify column data types
actions_col_types = cols(
  action_date = col_date(),
  action_time = col_time(),
  action_committee_systemCode = col_character(), 
  action_committee_name = col_character(), 
  action_source_code = col_character(),
  action_source_name = col_character(),
  action_text = col_character(), 
  action_type = col_character(), 
  action_code = col_character()
  )

# Convert column types
actions_df = type_convert(actions_df,
                          col_types = actions_col_types)

# Assign actions as data frame within a list
bill_df$actions = list(actions_df)
```

```{r}
#| eval: false
#| include: false
#| echo: false

bill_actions = xml_find_all(actions_node, "item")
    
bill_action_counts = as_list(xml_find_all(actions_node, "./*[not(self::item)]")) %>%
  map_dfc(flatten_dfc) %>% 
  rename_with(.cols = everything(), ~str_c("actions_", .)) %>% 
  pivot_longer(everything(), names_to = "action", names_prefix = "actions_", values_to = "count")

# Coerce nodes to list
actions_df = as_list(bill_actions) %>% 
  map_dfr(parse_action) %>% 
  type_convert(col_types = col_specs$actions)

bill_df$actions = list(actions_df)

bill_df$action_counts = list(type_convert(bill_action_counts,
                                          col_types = cols(action = col_character(), count = col_integer())))
```

### Nested XML

So we've dealt with cases with multiple child elements, but you can also have links to XML files within those child elements as you can see in the `<url>` element below.[^12]

[^12]: ![They heard you like XML so they put XML in your XML](https://c.tenor.com/um2EhyMQyR8AAAAC/xzibit-meme.gif){width="267"}

```{r}
#| label: vote-nodes-contents

# Find recordedVote nodes inside recordedVote container
bill_recorded_vote_nodes = xml_find_all(
  bill_node, 
  "recordedVotes/recordedVote"
  )

# Look at the nodeset contents
xml_contents(bill_recorded_vote_nodes)
```

Before we dive one level deeper, to start building our vote-level data frame, we can convert the top-level nodes to a list and flatten it into columns.

```{r}
#| label: vote-nodes-df
# Coerce nodes to list
recorded_votes_list = as_list(bill_recorded_vote_nodes)

(recorded_votes_df = map_dfr(recorded_votes_list, flatten_dfc)) %>% 
  glimpse()
```

::: {.callout-note appearance="simple"}
## Note

We use `flatten_dfc()` to flatten each vote element into a data frame as columns and then `map_dfr()` rolls them all up as rows into a single data frame.
:::

Now we want to get the vote roll XML file, so we'll need to use `read_xml()` . There are two main nodes - `<vote-metadata>` and `<vote-data>`. One node contains the aggregated vote information, while `<vote-data>` contains the legislator-level vote data. Let's parse the legislator-level data first. Here is the XML for a single legislator's vote:

```{r}
#| label: vote-roll-xml
vote_roll_xml = read_xml(recorded_votes_df$url)

vote_data = xml_find_all(vote_roll_xml, "vote-data")

vote_legislators = vote_data %>% 
  xml_find_all("recorded-vote")

(legislators_list = as_list(vote_legislators))[1] %>% 
  glimpse()

```

With a similar combination of `as_list()` , `flatten_dfr()`, and `unnest()` we can flatten the XML into one row per legislator but we lose all the attributes.

```{r}
#| label: vote-roll-data-flat
(vote_roll_flattened = vote_data %>% 
  as_list() %>% 
  flatten_dfr() %>% 
    unnest(everything()))
```

Instead we'll need to extract the attributes before we flatten the data. We want to extract the attributes only for legislator using `map()` to apply `map_at()` on each legislator element and extract the attributes from each while retaining the value in `vote`. It can often feel like you're getting lost in a list of lists, but with some experimentation you'll be able to find your way back to the surface.

```{r}
#| label: vote-roll-leg-df
(legislator_vote_df = legislators_list %>% 
    # Modify one level deeper using map_at to target legislator elements
    map(map_at, "legislator", attributes) %>% 
    map_dfr(flatten_dfc))
```

Now we have a table of legislator voting data! But what about the `<vote-metadata>`? Everything other than the `<vote-totals>` element is singular so we can get that out of the way the same way as before:

```{r}
#| label: vote-roll-metadata-xml
vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")

vote_singular_nodes = xml_singular_nodes(vote_metadata)

(vote_df = as_list(vote_singular_nodes) %>% 
  # as_list() doesn't retain element names so we set names ourselves
  setNames(xml_name(vote_singular_nodes)) %>% 
  flatten_dfc()) %>% 
  glimpse()
```

The `<vote-totals>` are a bit of a unique little element, with 3 different types of nodes. This is another opportunity for us to be choosy with our data. The first node is table headers, which we don't need because the elements are tagged anyway. From these, we really only need the `<totals-by-party>` nodes as long as the totals of which agree with `<totals-by-vote>` , which is worth checking.

```{r}
#| label: vote-roll-metadata-totals-contents
#| message: false
#| layout-nrow: 1
(vote_totals = xml_find_all(vote_metadata, "vote-totals")) %>% 
  xml_contents()

vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")

party_vote_totals_df = as_list(vote_totals_by_party) %>% 
  map_dfr(flatten_dfc) %>% 
    type_convert()

(totals_by_vote = xml_find_all(vote_totals, "totals-by-vote")) %>% 
  xml_contents()
```

Once we have our nodeset (which at last are all singular), we use the same listing, mapping, and flattening...or *lappening* as absolutely no one calls it.

```{r}
#| eval: false
#| include: false
# Check if totals match
as_list(totals_by_vote) %>% 
  map_dfr(flatten_dfc)

summarise(party_vote_totals, 
          across(.cols = -party, sum, na.rm=T))
# They do!
```

Now that we have all of our vote data wrangled from the thorny grasp of XML, we can put it all together and nest it until we've gotten back to the bill-level i.e. the vote roll data frame goes in the votes data frame, which goes in the bill data frame.

```{r}
#| label: vote-roll-build
vote_roll_df = vote_df %>% 
  mutate(legislator_votes = list(legislator_vote_df),
         party_votes = list(party_vote_totals_df)) %>% 
    janitor::clean_names()

(recorded_votes_df = recorded_votes_df %>% 
  mutate(vote_roll = list(vote_roll_df))) %>% 
  glimpse()

bill_df$votes = list(recorded_votes_df)
```

Now we have the bill-level characteristics with action and vote information nested in list columns. If we want to analyze the actions data, we simply have to `unnest()` it.

```{r}
#| label: unnest-actions
unnest(bill_df, actions) %>% 
  glimpse()
```

I'll stop there for brevity's sake, but you can find the code for extracting the full XML file [here](https://github.com/MokeEire/my-reps/blob/master/R/parsing_functions.R)[^13].

[^13]: Ctrl/Cmd+F: `extract_bill_status`

# TL;DR: Main Points

Transforming XML into a tabular format can be tricky depending on the structure. Start by understanding how the data is organized, what you want it to look like, and what level of detail you are looking at.

1.  **Explore the structure**

> Look through any available documentation, always. When you read in the XML file, functions like `xmlParse()`, `xml_structure()`, and `xml_contents()` will show you the structure you're dealing with.

2.  **Define the output**

> Consider what you want the output to look like and think about how the data needs to be transformed to match this.

3.  **Process a single element** (write a function if it gets too complicated)

> Get one element into the form you want. Writing functions can help you think through the data transformations being applied and make your code easier to read.

4.  **Apply to all elements**

> Focus on processing the entire file (or the subset of the file you're interested in). You might want an XML file to return a single row, a single column, or a data frame of size $n\times k$. Once you have a single file returned in the format you want, you can combine the outputs of all the files in your dataset.

Please reach out with any questions or feedback! All is welcome, and there may even be a reward for anyone who finds a mistake in the code.

```{r}
#| eval: false
#| include: false
parse_vote_roll = function(vote, logger, bill_type, bill_num){
  
  tryCatch(
    {
      vote_xml = read_xml(vote, options = "RECOVER")
      vote_data = xml_find_all(vote_xml, "vote-data")
      
      vote_roll_children = xml_children(vote_roll_xml)
      vote_data = xml_find_all(vote_roll_xml, "vote-data")
      
      # Vote data
      vote_legislators = vote_data %>% 
        xml_find_all("recorded-vote")
      legislators_list = as_list(vote_legislators)
      legislator_vote_df = legislators_list %>% 
        # Modify one level deeper using map_at to target legislator elements
        map(map_at, "legislator", attributes) %>% 
        map_dfr(flatten_dfc)
      
      # Vote metadata
      vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")
      vote_singular_nodes = xml_singular_nodes(vote_metadata)
      (vote_df = as_list(vote_singular_nodes) %>% 
          # as_list() doesn't retain element names so we set names ourselves
          setNames(xml_name(vote_singular_nodes)) %>% 
          flatten_dfc())
      
      # Vote totals
      vote_totals = xml_find_all(vote_metadata, "vote-totals")
      vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")
      party_vote_totals_df = vote_totals_by_party %>% 
        as_list() %>% 
        map_dfr(flatten_dfc) %>% 
        type_convert()
      
      vote_roll_df = vote_df %>% 
        mutate(legislator_votes = list(legislator_vote_df),
               party_votes = list(party_vote_totals_df)) %>% 
        janitor::clean_names()
      
      vote_list = as_list(vote_data)
      
      flatten_dfr(vote_list) %>% 
        unnest(everything())
    },
    error=function(cond) {
      log_info(logger, 
               bill_type = bill_type,
               bill_num = bill_num, 
               "ERROR: Vote roll could not be parsed")
      # Choose a return value in case of error
      return(tibble())
    }
  )
  
  
}
```

# Other helpful articles

Here are some of the helpful articles I came across in the course of writing this:

-   [From XML to Excel for Data Analysis](https://towardsdatascience.com/from-xml-to-excel-for-data-analysis-ac0c0c765b7d "Introduction to Processing XML In Python")
-   [Reading XML files in R](https://medium.com/geekculture/reading-xml-files-in-r-3122c3a2a8d9)
-   [Converting nested XML to dataframe in R](https://urbandatapalette.com/post/2021-03-xml-dataframe-r/)
-   [Parse and process XML (and HTML) with xml2](https://www.rstudio.com/blog/xml2/)

# Session Info

Version information about R, OS, and loaded packages.

```{r}
#| label: session-info
#| echo: false
sessioninfo::session_info("loaded")
```
