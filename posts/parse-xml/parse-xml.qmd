---
title: "Parsing XML with R"
subtitle: "Untangling congressional legislative data"
date: "2022-07-14"
categories: 
  - data
  - governance
  - R
format: 
  html: 
    toc: true
    code-link: true
    code-fold: show
    code-tools: true
    comments:
      hypothesis: true
---

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false
library(extrafont)
library(reactable)

source("https://github.com/MokeEire/my-reps/raw/master/R/parsing_functions.R")
bill_xml_url = "https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml"
bill_xml_file = read_xml(bill_xml_url)

```

Unlike Excel spreadsheets, CSV files, and other tabular formats, (e)Xtensible Markup Language (XML) is a storage format designed to contain any "arbitrary" structure[^1] of data. XML's flexibility is useful for storing information like financial transactions and recipes to webpage content and document formatting[^2]. If you have worked with XML before, you'll know it can be a bit of a pain to transform into a tabular format typically used in data analysis. The good news is you're not alone! This article will help you to load XML files with R, extract what you need from them, and store the results in a analysis-friendly data frame.

[^1]: [Wikipedia](https://en.wikipedia.org/wiki/XML) for the curious. Don't miss the drama about Microsoft's "vociferous protests" as one of the co-editors started working with Netscape.

[^2]: The *x* at the end of Microsoft file types (e.g. .docx, .xlsx, .pptx) stands for XML.

::: {.callout-tip appearance="simple"}
## What you'll learn:

-   Load and parse XML files in R using the `{XML}` and `{xml2}` packages

-   Explore the structure of XML documents

-   List, map, and flatten your data into a tabular format using `{purrr}`, and making use of `{tidyr}`'s list columns when necessary
:::

# What is XML?

At its core, XML is "information wrapped in tags". Think of XML's structure as branches of a tree, with each branch having their own leaves. Below is an example of a bookstore's data in XML format from [w3schools](https://www.w3schools.com/XML/xml_usedfor.asp).

``` xml
<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>
```

`<bookstore>` is the parent, or *root* element in the example above. The two `<book>` elements are the bookstore's *children*, each of which has individual data points in *child* elements (e.g. `<title>`) and *attributes* e.g. `<book category="children">` stores the book's category as an attribute.

::: {.callout-note appearance="minimal"}
## Note

Attributes are a useful way to store data related to a specific element for HTML, but using child elements is typically preferred in XML[^3]. However, you'll still likely run into data stored in attributes so we'll touch on extracting data from both.
:::

[^3]: To learn more about what XML is and how to use it, I recommend going through [w3school's XML tutorial](https://www.w3schools.com/XML/default.asp).

# Navigating XML with R

If you've never used R before, this will be a bit of a rough point to start learning. Instead I would recommend checking [RStudio's beginners guide](https://education.rstudio.com/learn/beginner/), so for the remainder of the post I will assume some familiarity with R. Four packages I use throughout this post are listed below. If you don't understand how a function works or want to see the function reference, click on the function in the code and it *should* bring you to the function's help page.

-   `{XML}` and `{xml2}` provide functions for reading in and parsing XML[^4]

-   `{purrr}` and `{tidyr}` (loaded as part of the `{tidyverse}` package) help us wrangle lists and transform XML to data frames.

[^4]: Between `{XML}` and `{xml2}` there are numerous ways to load XML data with R. I generally prefer `{xml2}` but I suggest looking through the packages' documentation to find the right function for your task

```{r}
#| label: load-libs
#| code-fold: show
#| code-summary: "Load libraries"
# copy the comment below to install the packages
# install.packages(c("tidyverse", "XML", "xml2))
library(tidyverse)
library(XML)
library(xml2)

```

To illustrate potential complexities of XML structures I'll be using [congressional bill status data](https://www.govinfo.gov/bulkdata/BILLSTATUS) from the US GPO's [GovInfo service](https://www.govinfo.gov/). In particular, you can download the sample bill [here](https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml "HR-391: Global Health Security Act of 2021") (chosen for its examples of challenges parsing XML).

First we need to read in the XML file. You can pass the URL or file path of the XML file to `read_xml()` to create an `xml_document` object[^5]. To see the contents of the file you've just loaded you can use `xml_contents()` or enter the object's name (here `bill_xml`) in the console.

[^5]: `xml_document` is one of the "key classes" used in the `{xml2}` library, the others being `xml_node` (a single node), and `xml_nodeset` (a set of nodes).

```{r}
#| label: read-xml
#| code-fold: show
#| code-summary: "Load and view XML file"

# Read XML file
bill_xml = read_xml("https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml")

# Look at xml_document's contents
xml_contents(bill_xml)

```

We have two top-level nodes - `<bill>` and `<dublinCore>`[^6]. The latter is actually a metadata identifier and doesn't contain bill-related information. We can use `xml_child()` to select only elements inside the `<bill>` node, returning an XML nodeset that looks like this:

[^6]: Which is a document metadata identifier, not an Irish metal music genre. While very useful in its own right, it isn't relevant for our task here.

```{r}
#| label: xml-bill-child
#| code-fold: show
#| column: page-right
#| code-summary: "Select first matching child element"

(bill_node = xml_child(bill_xml, "bill"))

```

# Define the output

Now we have the bill XML loaded and we've already stripped away some data we don't need but before diving deeper, it's helpful to think about the how you want to the processed XML data to be structured. For example, in the bill status data I might want to collect party-level votes. This could take the form of one row per party per bill with a column for yeas, nays, and abstentions[^7]. Perhaps I want to look at the policy areas of bills which became law. Instead of processing the entire file and then selecting the data I want, I can select only the nodes I need at the outset before transforming the data into a data frame. This will likely save you some time in cases where you have a lot of data.

[^7]: For example

    | Bill     | Party    | $\cdots$ | Yeas     | Nays     | Abstentions |
    |----------|----------|----------|----------|----------|-------------|
    | HR-1     | R        | $\cdots$ | 221      | 0        | 1           |
    | HR-1     | D        | $\cdots$ | 0        | 212      | 1           |
    | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$    |

    : Potential structure for party-level votes

```{r}
#| label: example-bill
#| echo: false
#| message: false
#| column: page

example_bill_df = extract_bill_status(bill_xml_url, log_types = NULL)

```

With the congressional bills data, I defined my output as a bill-level dataset, i.e. one bill per row, storing *nested* elements like `recordedVotes`, `committees`, and `actions` inside [list columns](https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html). While columns in a data frame are typically *atomic vectors*[^8] of equal length, list columns enable us to store data of varying length and type, including data frames themselves. Using `{tidyr}`'s `unnest()` function, we can expand this nested data into regular data frame columns. Here is what this output will look like:

[^8]: Atomic vectors are vectors with elements of the same type (e.g. numeric, character, etc.) as opposed to *general vectors*, or lists, which can contain a variety of types.

```{r}
#| label: example-bill-rt
#| echo: false
#| eval: true
#| column: page
example_bill_df %>% #glimpse() # here to check the data
  reactable::reactable(
    theme = moke_rt(),
    compact = T,
    resizable = T,
    wrap = F,
    columns = list(
      "bill_id" = colDef(show=F),
      "bill_number" = colDef(name = "Bill No.", width = 80),
      "create_date" = colDef(format = colFormat(date = T), width = 100),
      "update_date" = colDef(format = colFormat(date = T), width = 100),
      "origin_chamber" = colDef(show=F),
      "bill_type" = colDef(name = "Bill type", width = 60),
      "introduced_date" = colDef(format = colFormat(date = T), width = 130),
      "congress" = colDef(width = 80),
      "constitutional_authority_statement_text" = colDef(show=F),
      "title" = colDef(minWidth = 180),
      "version" = colDef(show = F, width = 80),
      "policy_areas" = colDef(width = 120),
      "legislative_subjects" = colDef(width = 200),
      "bill_summaries" = colDef(show=F),
      "bill_titles" = colDef(show=F),
      "bill_text_versions" = colDef(show=F),
      "latest_action_action_date" = colDef(name = "action_date", 
                                           width = 110,
                                           format = colFormat(date = T)),
      "latest_action_text" = colDef(name = "action_text",
                                    minWidth = 200),
      "committees" = colDef(minWidth = 80),
      "house_votes" = colDef(width = 80),
      "senate_votes" = colDef(width = 80),
      "actions" = colDef(width = 80),
      "action_counts" = colDef(show=F),
      "sponsors" = colDef(width = 80),
      "cosponsors" = colDef(width = 80)
    ), 
    columnGroups = list(
      colGroup(name = "Latest Action",
                            columns = c("latest_action_action_date",
                                        "latest_action_text")),
      colGroup(name = "Nested Data",
                            columns = c("committees", "house_votes", 
                                        "senate_votes", "actions", 
                                        "sponsors", "cosponsors"))
    )
  )

```

Here's a `glimpse()` of some of the nested data:

::: panel-tabset
## Committees

```{r}
#| label: glimpse-committees
#| echo: false

glimpse(example_bill_df[["committees"]], width = 100)

```

## Votes

```{r}
#| label: glimpse-votes
#| echo: false

glimpse(example_bill_df[["house_votes"]], width = 90)

```

## Actions

```{r}
#| label: glimpse-actio
#| echo: false
glimpse(example_bill_df[["actions"]], width = 80)
```

## Sponsors

```{r}
#| label: glimpse-sponsors
#| echo: false
glimpse(example_bill_df[["sponsors"]], width = 70)
```
:::

# From XML to Data Frame

How your XML is structured, and how you want to structure your tabular output will determine how you need to process the XML file. In general, this will involve the following steps:

1.  Select the XML nodes you want to include in your dataset.
2.  Convert the XML to a list.
3.  `flatten()` the list into a data frame.

::: callout-tip
## Write Functions

If you find yourself doing similar transformations in multiple cases or copy-pasting some piece of code more than once, I would implore you to write functions because they:

1.  make your code more reliable
2.  make you think critically about how you're modifying the data
3.  are easier to debug

A good resource to start learning about writing functions is [How to Write a Function in R](https://www.earthdatascience.org/courses/earth-analytics/automate-science-workflows/write-function-r-programming/).
:::

## Singular elements

You can think of singular elements as the contents of a single cell in a data frame. In the bookstore example, you could arrange each book as a row and each child node as a column.

```{r}
bookstore_xml_text = '<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>'

bookstore_xml_parsed = xmlParse(bookstore_xml_text)

(bookstore_xml_df = xmlToDataFrame(bookstore_xml_parsed))
```

In cases where your data are entirely singular nodes, you can convert XML to a dataframe using two functions from `{XML}`[^9]: `xmlParse()` and `xmlToDataFrame()`. Because the congressional data has singular and nested element structures, the nested data in fields like `committees`, `actions`, and `sponsors` are combined into single columns. If your data is not all singular nodes like this, you'll need to do a little bit more work to get the data into a [tidy data](https://vita.had.co.nz/papers/tidy-data.html) frame.

[^9]: When you're working with both the `{XML}` and `{xml2}` libraries, it is important to note that their functions often rely on different object types. In the case of `xmlToDataFrame()`, it does not take `{xml_document}` or `{xml_node}` objects. If you try to use them, you'll see an error like this:

    ```{r}
    #| label: xml-df-error
    #| error: true

    xmlToDataFrame(bill_xml)
    ```

```{r}
#| label: xml-to-df

# First you need to use the xmlParse function
bill_xml_parse = xmlParse(bill_xml)

xmlToDataFrame(getNodeSet(bill_xml_parse, "//bill")) %>% 
  glimpse()
```

::: callout-note
## Note

In this example, we actually need to use `getNodeSet(., [path =] "//bill")` to select only nodes in `<bill>`. If we just passed `bill_xml_parse`, we would get a dataframe with two rows because the top-level nodes are bill and the metadata identifier node `<dublinCore>`.
:::

To start building our congressional bill dataset, we need to isolate singular elements like `billNumber` and `billType` by selecting nodes which meet two criteria: 1) the node does not have any child nodes of its own, and 2) the node is not an empty string. I use to extract nodes based on an [XPath](https://www.w3schools.com/xml/xml_parser.asp) (XML Path Language) string. It returns an `{xml_nodeset}` which is then coerced to a list using `as_list()`.

As the help file for `xml_find_all()` says, "XPath is like regular expressions for trees". The expression selects the nodes which match the given path or pattern[^10]. In the code below `//bill/*` selects the child nodes in a bill. The expressions `[` within the square brackets `]` are called predicates which I use to find nodes which have no children with the XPath `count` function and nodes which are not empty strings[^11].

[^10]: [A very useful table of XPath syntax](https://www.w3schools.com/XML/xpath_syntax.asp){target="_blank"}

[^11]: In the process of writing this, I discovered that using XPath made this \~5x faster than an equivalent function in R.

    ```{r}
    #| label: singular-nodes
    #| code-fold: show
    # Function to select singular child nodes from XML node
    xml_singular_nodes = function(xml_node){
      # Return child nodes of current node
      child_nodes = xml_children(xml_node)
      # Select child nodes with 0 children
      zero_length_child_nodes = child_nodes[xml_length(child_nodes) == 0]
      
      # Keep the nodes which are not empty strings
      keep(zero_length_child_nodes, ~(xml_text(.) != ""))
    }

    ```

    ```{r}
    #| label: bench-node-selection

    # Using XPath:
    # singular_nodes1 = xml_find_all(bill_xml, 
    #                                 "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")

    # Using R function:
    # singular_nodes2 = xml_singular_nodes(bill_node)

    # Check they are the same
    # all.equal(singular_nodes1, singular_nodes2)

    # benchmark the two different ways of selecting nodes
    microbenchmark::microbenchmark(
      xml_singular_nodes = xml_singular_nodes(bill_node),
      xml_find_all = xml_find_all(bill_xml, "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")
    )
    ```

```{r}
#| label: singular-nodes-list
#| code-fold: show

singular_nodes = xml_find_all(
  bill_xml, 
  "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]"
  )

(singular_list = as_list(singular_nodes)) %>% 
  glimpse()
```

Note that we didn't retain the element names so we need to assign them ourselves. When your data is in a named list, you can flatten each element in the list into a **d**ata **f**rame **c**olumn using purrr's `flatten_dfc()` .

```{r}
#| label: singular-nodes-list-named
#| code-fold: show
singular_list_named = setNames(singular_list, 
                                xml_name(singular_nodes))

(bill_df = flatten_dfc(singular_list_named)) %>% 
  glimpse()
```

```{r}
#| label: singular-nodes-rt
#| column: page
#| echo: false
#| eval: false
reactable(bill_df,
          theme = moke_rt(),
            columns = list(
              "constitutionalAuthorityStatementText" = colDef(show=F),
              "createDate" = colDef(format = colFormat(date = T), width = 100),
              "updateDate" = colDef(format = colFormat(date = T), width = 100),
              "introducedDate" = colDef(format = colFormat(date = T), width = 120),
              "congress" = colDef(width = 90),
              "originChamber" = colDef(show=F),
              "version" = colDef(show=F, width = 80),
              "billNumber" = colDef(width = 105),
              "billType" = colDef(width = 85),
              "title" = colDef(minWidth = 180)
            ))
```

## Nested elements

Parsing XML when your data is all singular is straightforward, but often XML will use a nested data structure. In this case the congressional data, actions and votes on each bill are stored in their own container elements. We can transform the data in these containers to nested data frames and use the `nest()`/`unnest()` functionality of `{tidyr}` to change the level of observation as needed.

To create each data frame, we isolate the nodes using XPath, and use the same steps as before to convert the XML to a list and then nest them in a list column.

### Multiple children with sub-elements

Actions are stored in a container node where each `<item>` represents a congressional action taken for a bill, such as being introduced, sent to a committee, debated on the floor, etc. Just as before, we use `as_list()` to convert the `{xml_nodeset}` to a list.

```{r}
#| label: actions-list
#| code-fold: show

actions_xml = xml_find_all(bill_node, "actions/item")

actions_list = as_list(actions_xml)

# Look at first action
glimpse(actions_list[[1]], width = 50)
```

For an individual action, we have the date, a list of committees related to the action, some administrative information, the text and type of action. To deal with this, we can write a function (or set of functions) like the ones below to transform actions from a list to a data frame with their own nested elements.

```{r}
#| label: actions-functions
#| code-fold: true
#| code-summary: "View Functions"
# Helper function: flatten_dfc_rename
# flatten a list to data frame and 
# rename the columns with a given prefix
flatten_dfc_rename = function(list_to_flatten, 
                          name_prefix = "prefix"){
  rename_with(
    .data = flatten_dfc(list_to_flatten), 
    .fn = ~str_c(name_prefix, "_", .),
    # Exclude columns which already start with the prefix
    .cols = -starts_with(name_prefix)
    )
}

# Function: parse_action
# Parse actions from list to data frame
parse_action = function(action){
  action %>% 
    # Flatten + rename sourceSystem elements
    map_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten + rename committees
    map_at("committees", function(committee){
      # using map_at and map_dfr to create a data frame row for each committee
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    # Lastly, clean the names
    janitor::clean_names()
}

```

```{r}
#| label: benchmark-parse-action
#| eval: false
#| include: false
# Test modify_at vs map_at
parse_action2 = function(action){
  action %>% 
    # Flatten+rename  sourceSystem elements
    modify_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten+rename committees
    modify_at("committees", function(committee){
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    janitor::clean_names()
}

# Parse the first action
parse_action2(actions_list[[1]])

# What about speed?
microbenchmark::microbenchmark(
  parse_action = parse_action(actions_list[[1]]),
  parse_action2 = parse_action2(actions_list[[1]]), times = 1000
)
```

Using the `{purrr}` library's `map_dfr()`, we apply this function to each action and combine the results into **d**ata **f**rame **r**ows. Here's the output of this process:

```{r}
# Parse the first action
(actions_df = map_dfr(actions_list, parse_action)) %>% 
  glimpse()
```

When you plan to combine rows into a data frame or `unnest()` the data in the future, it is useful to be explicit about the expected data types of each column. This can be done using `type_convert()`. Because we are only adding a single row of data to `bill_df` we can encase the actions in a list and use dollar assignment. If you were adding multiple rows of data, you would need to make sure that you are adding a column of the same length as `bill_df`.

```{r}
#| label: actions-dfr
#| code-fold: show

# Specify column data types
actions_col_types = cols(
  action_date = col_date(),
  action_time = col_time(),
  action_committee_systemCode = col_character(), 
  action_committee_name = col_character(), 
  action_source_code = col_character(),
  action_source_name = col_character(),
  action_text = col_character(), 
  action_type = col_character(), 
  action_code = col_character()
  )

# Convert column types
actions_df = type_convert(actions_df,
                          col_types = actions_col_types)

# Assign actions as data frame within a list
bill_df$actions = list(actions_df)
```

```{r}
#| eval: false
#| include: false
#| echo: false

bill_actions = xml_find_all(actions_node, "item")
    
bill_action_counts = as_list(xml_find_all(actions_node, "./*[not(self::item)]")) %>%
  map_dfc(flatten_dfc) %>% 
  rename_with(.cols = everything(), ~str_c("actions_", .)) %>% 
  pivot_longer(everything(), names_to = "action", names_prefix = "actions_", values_to = "count")

# Coerce nodes to list
actions_df = as_list(bill_actions) %>% 
  map_dfr(parse_action) %>% 
  type_convert(col_types = col_specs$actions)

bill_df$actions = list(actions_df)

bill_df$action_counts = list(type_convert(bill_action_counts,
                                          col_types = cols(action = col_character(), count = col_integer())))
```

### Nested XML

So we've dealt with cases with multiple child elements, but you can also have links to XML files within those child elements as you can see in the `<url>` element below.[^12]

[^12]: ![They heard you like XML so they put XML in your XML](https://c.tenor.com/um2EhyMQyR8AAAAC/xzibit-meme.gif){width="267"}

```{r}
#| label: vote-nodes-contents

# Find recordedVote nodes inside recordedVote container
bill_recorded_vote_nodes = xml_find_all(
  bill_node, 
  "recordedVotes/recordedVote"
  )

# Look at the nodeset contents
xml_contents(bill_recorded_vote_nodes)
```

Before we dive one level deeper, to start building our vote-level data frame, we can convert the top-level nodes to a list and flatten it into columns.

```{r}
#| label: vote-nodes-df
# Coerce nodes to list
recorded_votes_list = as_list(bill_recorded_vote_nodes)

(recorded_votes_df = map_dfr(recorded_votes_list, flatten_dfc)) %>% 
  glimpse()
```

::: {.callout-note appearance="simple"}
## Note

We use `flatten_dfc()` to flatten each vote element into a data frame as columns and then `map_dfr()` rolls them all up as rows into a single data frame.
:::

Now we want to get the vote roll XML file, so we'll need to use `read_xml()` . There are two main nodes - `<vote-metadata>` and `<vote-data>`. One node contains the aggregated vote information, while `<vote-data>` contains the legislator-level vote data. Let's parse the legislator-level data first. Here is the XML for a single legislator's vote:

```{r}
#| label: vote-roll-xml
vote_roll_xml = read_xml(recorded_votes_df$url)

vote_data = xml_find_all(vote_roll_xml, "vote-data")

vote_legislators = vote_data %>% 
  xml_find_all("recorded-vote")

(legislators_list = as_list(vote_legislators))[1] %>% 
  glimpse()

```

With a similar combination of `as_list()` , `flatten_dfr()`, and `unnest()` we can flatten the XML into one row per legislator but we lose all the attributes.

```{r}
#| label: vote-roll-data-flat
(vote_roll_flattened = vote_data %>% 
  as_list() %>% 
  flatten_dfr() %>% 
    unnest(everything()))
```

Instead we'll need to extract the attributes before we flatten the data. We want to extract the attributes only for legislator using `map()` to apply `map_at()` on each legislator element and extract the attributes from each while retaining the value in `vote`. It can often feel like you're getting lost in a list of lists, but with some experimentation you'll be able to find your way back to the surface.

```{r}
#| label: vote-roll-leg-df
(legislator_vote_df = legislators_list %>% 
    # Modify one level deeper using map_at to target legislator elements
    map(map_at, "legislator", attributes) %>% 
    map_dfr(flatten_dfc))
```

Now we have a table of legislator voting data! But what about the `<vote-metadata>`? Everything other than the `<vote-totals>` element is singular so we can get that out of the way the same way as before:

```{r}
#| label: vote-roll-metadata-xml
vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")

vote_singular_nodes = xml_singular_nodes(vote_metadata)

(vote_df = as_list(vote_singular_nodes) %>% 
  # as_list() doesn't retain element names so we set names ourselves
  setNames(xml_name(vote_singular_nodes)) %>% 
  flatten_dfc()) %>% 
  glimpse()
```

The `<vote-totals>` are a bit of a unique little element, with 3 different types of nodes. This is another opportunity for us to be choosy with our data. The first node is table headers, which we don't need because the elements are tagged anyway. From these, we really only need the `<totals-by-party>` nodes as long as the totals of which agree with `<totals-by-vote>` , which is worth checking.

```{r}
#| label: vote-roll-metadata-totals-contents
#| message: false
#| layout-nrow: 1
(vote_totals = xml_find_all(vote_metadata, "vote-totals")) %>% 
  xml_contents()

vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")

party_vote_totals_df = as_list(vote_totals_by_party) %>% 
  map_dfr(flatten_dfc) %>% 
    type_convert()

(totals_by_vote = xml_find_all(vote_totals, "totals-by-vote")) %>% 
  xml_contents()
```

Once we have our nodeset (which at last are all singular), we use the same listing, mapping, and flattening...or *lappening* as absolutely no one calls it.

```{r}
#| eval: false
#| include: false
# Check if totals match
as_list(totals_by_vote) %>% 
  map_dfr(flatten_dfc)

summarise(party_vote_totals, 
          across(.cols = -party, sum, na.rm=T))
# They do!
```

Now that we have all of our vote data wrangled from the thorny grasp of XML, we can put it all together and nest it until we've gotten back to the bill-level i.e. the vote roll data frame goes in the votes data frame, which goes in the bill data frame.

```{r}
#| label: vote-roll-build
vote_roll_df = vote_df %>% 
  mutate(legislator_votes = list(legislator_vote_df),
         party_votes = list(party_vote_totals_df)) %>% 
    janitor::clean_names()

(recorded_votes_df = recorded_votes_df %>% 
  mutate(vote_roll = list(vote_roll_df))) %>% 
  glimpse()

bill_df$votes = list(recorded_votes_df)
```

Now we have the bill-level characteristics with action and vote information nested in list columns. If we want to analyze the actions data, we simply have to `unnest()` it.

```{r}
#| label: unnest-actions
unnest(bill_df, actions) %>% 
  glimpse()
```

I'll stop there for brevity's sake, but you can find the code for extracting the full XML file [here](https://github.com/MokeEire/my-reps/blob/master/R/parsing_functions.R)[^13].

[^13]: Ctrl/Cmd+F: `extract_bill_status`

# TL;DR: Main Points

Transforming XML into a tabular format can be tricky depending on the structure. Start by understanding how the data is organized, what you want it to look like, and what level of detail you are looking at.

1.  **Explore the structure**

> Look through any available documentation, always. When you read in the XML file, functions like `xmlParse()`, `xml_structure()`, and `xml_contents()` will show you the structure you're dealing with.

2.  **Define the output**

> Consider what you want the output to look like and think about how the data needs to be transformed to match this.

3.  **Process a single element** (write a function if it gets too complicated)

> Get one element into the form you want. Writing functions can help you think through the data transformations being applied and make your code easier to read.

4.  **Apply to all elements**

> Focus on processing the entire file (or the subset of the file you're interested in). You might want an XML file to return a single row, a single column, or a data frame of size $n\times k$. Once you have a single file returned in the format you want, you can combine the outputs of all the files in your dataset.

Please reach out with any questions or feedback! All is welcome, and there may even be a reward for anyone who finds a mistake in the code.

```{r}
#| eval: false
#| include: false
parse_vote_roll = function(vote, logger, bill_type, bill_num){
  
  tryCatch(
    {
      vote_xml = read_xml(vote, options = "RECOVER")
      vote_data = xml_find_all(vote_xml, "vote-data")
      
      vote_roll_children = xml_children(vote_roll_xml)
      vote_data = xml_find_all(vote_roll_xml, "vote-data")
      
      # Vote data
      vote_legislators = vote_data %>% 
        xml_find_all("recorded-vote")
      legislators_list = as_list(vote_legislators)
      legislator_vote_df = legislators_list %>% 
        # Modify one level deeper using map_at to target legislator elements
        map(map_at, "legislator", attributes) %>% 
        map_dfr(flatten_dfc)
      
      # Vote metadata
      vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")
      vote_singular_nodes = xml_singular_nodes(vote_metadata)
      (vote_df = as_list(vote_singular_nodes) %>% 
          # as_list() doesn't retain element names so we set names ourselves
          setNames(xml_name(vote_singular_nodes)) %>% 
          flatten_dfc())
      
      # Vote totals
      vote_totals = xml_find_all(vote_metadata, "vote-totals")
      vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")
      party_vote_totals_df = vote_totals_by_party %>% 
        as_list() %>% 
        map_dfr(flatten_dfc) %>% 
        type_convert()
      
      vote_roll_df = vote_df %>% 
        mutate(legislator_votes = list(legislator_vote_df),
               party_votes = list(party_vote_totals_df)) %>% 
        janitor::clean_names()
      
      vote_list = as_list(vote_data)
      
      flatten_dfr(vote_list) %>% 
        unnest(everything())
    },
    error=function(cond) {
      log_info(logger, 
               bill_type = bill_type,
               bill_num = bill_num, 
               "ERROR: Vote roll could not be parsed")
      # Choose a return value in case of error
      return(tibble())
    }
  )
  
  
}
```

# Other helpful articles

Here are some of the helpful articles I came across in the course of writing this:

-   [From XML to Excel for Data Analysis](https://towardsdatascience.com/from-xml-to-excel-for-data-analysis-ac0c0c765b7d "Introduction to Processing XML In Python")
-   [Reading XML files in R](https://medium.com/geekculture/reading-xml-files-in-r-3122c3a2a8d9)
-   [Converting nested XML to dataframe in R](https://urbandatapalette.com/post/2021-03-xml-dataframe-r/)
-   [Parse and process XML (and HTML) with xml2](https://www.rstudio.com/blog/xml2/)

# Session Info

Version information about R, OS, and loaded packages.

```{r}
#| label: session-info
#| echo: false
sessioninfo::session_info("loaded")
```
