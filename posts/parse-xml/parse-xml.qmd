---
title: "Parsing XML with R"
subtitle: "Untangling congressional legislative data"
date: "2022-07-14"
categories: 
  - data
  - governance
  - R
format: 
  html: 
    toc: true
    code-link: true
    code-fold: show
    code-tools: true
    comments:
      hypothesis: true
---

```{r}
#| label: setup
#| message: false
#| warning: false
#| echo: false
library(extrafont)
library(reactable)

source("https://github.com/MokeEire/my-reps/raw/master/R/parsing_functions.R")
bill_xml_link = "https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml"
bill_xml_file = read_xml(bill_xml_link)
```

```{r}
#| label: df-print-fct
#| include: false

knit_print.data.frame = function(x, ...){
  knitr::knit_print(
    reactable(x,
              compact = T, 
              resizable = T,
              ),
    ...
    )
}
```

::: {.callout-tip appearance="simple"}
## What you'll learn:

-   Load and parse XML files in R using the `{XML}` and `{xml2}` packages

-   Explore the structure of XML documents

-   List, map, and flatten your data into a tabular format using `{purrr}` and using list columns with `{tidyr}`
:::

# What is XML?

If someone asked me what my least favourite data format to work with is, I would of course say PDF, but XML would not be far behind it. Unlike Excel spreadsheets, text files, and other tabular formats, (e)Xtensible Markup Language (XML) is designed to store any "arbitrary" structure[^1] of data. This flexibility makes XML useful for all kinds of information from financial transactions and recipes to webpage content and document formatting[^2]. Although working with XML may not be as simple as with tabular data, the contents can be much richer.

[^1]: [Wikipedia](https://en.wikipedia.org/wiki/XML) for the curious. Don't miss the drama about Microsoft's "vociferous protests" as one of the co-editors started working with Netscape.

[^2]: The *x* at the end of Microsoft file types (e.g. .docx, .xlsx, .pptx) stands for XML.

At its core, XML is just "information wrapped in tags". Here is an example from [w3schools](https://www.w3schools.com/XML/xml_usedfor.asp) of information a bookstore might have in XML format:

``` xml
<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>
```

The `<bookstore>` parent, or *root* element contains child elements called `<book>` which themselves have child elements -- `<title>`, `<author>`, `<year>`, and `<price>`. XML can be thought of as a tree, where each tree branch can have multiple leaves, or none.

Note the book elements also have `category` attributes. Attributes are a useful way to store data related to a specific element for HTML, but using child elements is typically preferred in XML. This post will touch on data stored using both methods. To learn more about what XML is and how to use it, I recommend going through [w3school's XML tutorial](https://www.w3schools.com/XML/default.asp).

# Navigating XML with R

To illustrate potential complexities of XML structures, I'll be using congressional bill data provided by the [United States Government Publishing Office (GPO)](https://www.gpo.gov/). To follow along, you can download the sample XML bill [here](https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml "HR-391: Global Health Security Act of 2021")[^3]. As always, the first step of data analysis is to look at the documentation. Luckily, GovInfo provides a [user guide](https://github.com/usgpo/bill-status/blob/main/BILLSTATUS-XML_User_User-Guide.md) for the Bill Status data.

[^3]: I chose the bill [*HR-391: Global Health Security Act of 2021*](https://www.govinfo.gov/app/details/BILLS-117hr391rfs)only because it contains good examples of the challenges of parsing XML data, so consider this a standard *retweets â‰  endorsements* situation*.*

In terms of R packages, four are most important for this article. `{XML}` and `{xml2}`[^4] provide functions for reading in XML data while `{purrr}` and `{tidyr}` (loaded as part of the `{tidyverse}` package) helps us parse and flatten the data into tabular form. To start, read in the file with `read_xml()` , which returns an `xml_document`[^5] object.

[^4]: Between `{XML}` and `{xml2}` there are numerous ways to load XML data with R. I generally prefer `{xml2}` but I suggest looking through the packages' documentation to find the right function for your task

[^5]: `xml_document` is one of the "key classes" used in the `{xml2}` library, the others being `xml_node` (a single node), and `xml_nodeset` (a set of nodes).

```{r}
#| label: read-xml
#| code-fold: show
#| code-summary: "Load and view XML file"

library(tidyverse)
library(XML)
library(xml2)


bill_xml = read_xml("https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml")

# Look at the xml_document's contents
xml_contents(bill_xml)
```

We can see the document has two top-level nodes - one `<bill>` node and one called `<dublinCore>`[^6] In this case we can look just at the `<bill>` node using `xml_child()`.

[^6]: Which is a document metadata identifier, not an Irish metal music genre. While very useful in its own right, it isn't relevant for our task here.

```{r}
#| code-fold: show
#| label: xml-bill-child
#| code-overflow: wrap
# Return child nodes named bill

(bill_node = xml_child(bill_xml, "bill"))
```

So if we want to have a data frame with one row per bill, we have a few different kinds of elements to deal with. Firstly there are the elements which have **only one value** (i.e. *singular*) like `billNumber`, `createDate`, and `billType`. There are also elements which have information *nested* in them like `recordedVotes`, `committees`, and `actions`.

The importance of understanding the structure of your data brings us to one of the cardinal rules of data analysis:

::: callout-tip
## Look at your data

In fact, you could even say *stare* at it. Understanding the structure and contents of your data is essential for designing a solution to consistently process the data.
:::

# Define the output

As well as looking at your data, it's also helpful to think about your intended output. This determines what you need to do to transform the data. Depending on the structure of your XML data, there are a lot of different options.

In the case of congressional data, we have multiple levels of observation - bill, action, vote, and individual legislator votes. To organize the data in a way that preserves each, we can use rows, columns, separate tables linked by some combination of ID variables, or we can use [list columns](https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html). Columns in a data frame are typically *atomic vectors*[^7] of equal length, but list columns enable us to store data of varying length and type, including data frames themselves. This makes them a perfect solution for the nested characteristics of the congressional data. Using `{tidyr}`, we will `nest()`/`unnest()` these columns as needed. The end result will look like this:

[^7]: Atomic vectors are vectors with elements of the same type (e.g. numeric, character, etc.) as opposed to *general vectors*, or lists, which can contain a variety of types.

```{r}
#| label: example-bill
#| echo: false
#| message: false

example_bill_df = extract_bill_status(bill_xml_link, log_types = NULL)

glimpse(example_bill_df)
```

```{r}
#| label: example-bill-rt
#| echo: false
#| eval: false
example_bill_df %>% #glimpse() # here to check the data
  # select(
  #   -bill_id, -where(is_list) # remove list columns?
  # ) %>%
  reactable::reactable(
    theme = moke_rt(),
    compact = T,
    resizable = T,
    wrap = F,
    columns = list(
      "bill_number" = colDef(width = 100),
      "create_date" = colDef(format = colFormat(date = T), width = 100),
      "update_date" = colDef(format = colFormat(date = T), width = 100),
      "origin_chamber" = colDef(show=F),
      "bill_type" = colDef(width = 80),
      "introduced_date" = colDef(format = colFormat(date = T), width = 130),
      "congress" = colDef(width = 80),
      "constitutional_authority_statement_text" = colDef(show=F),
      "title" = colDef(minWidth = 180),
      "version" = colDef(show = F, width = 80),
      "policy_areas" = colDef(width = 120),
      "legislative_subjects" = colDef(width = 200),
      "bill_summaries" = colDef(show=F),
      "bill_titles" = colDef(show=F),
      "bill_text_versions" = colDef(show=F),
      "latest_action_action_date" = colDef(name = "action_date", 
                                           width = 110,
                                           format = colFormat(date = T)),
      "latest_action_text" = colDef(name = "action_text",
                                    minWidth = 200),
      "committees" = colDef(minWidth = 80),
      "votes" = colDef(width = 80),
      "actions" = colDef(width = 80),
      "action_counts" = colDef(show=F),
      "sponsors" = colDef(width = 80),
      "cosponsors" = colDef(width = 80)
    ), 
    columnGroups = list(
      colGroup(name = "Latest Action",
                            columns = c("latest_action_action_date",
                                        "latest_action_text")),
      colGroup(name = "Nested Data",
                            columns = c("committees", "votes", "actions", 
                                        "sponsors", "cosponsors"))
    )
  )
```

Here's a `glimpse()` of some of the nested data:

::: panel-tabset
## Committees

```{r}
#| label: glimpse-committees
#| echo: false
glimpse(example_bill_df[["committees"]])

```

## Votes

```{r}
#| label: glimpse-votes
#| echo: false
glimpse(example_bill_df[["votes"]])

```

## Actions

```{r}
#| label: glimpse-actio
#| echo: false
glimpse(example_bill_df[["actions"]])
```

## Sponsors

```{r}
#| label: glimpse-sponsors
#| echo: false
glimpse(example_bill_df[["sponsors"]])
```
:::

# Parsing

With an understanding of your data's structure and your intended output, let's break down the process into extracting 1) singular elements i.e. only one value, and 2) nested elements. Your output should inform what you do with both, but for either case I convert XML to a list and use `{purrr]` to flatten and transform the list into a data frame.

::: callout-tip
## Write Functions

For more complex cases, I would implore you to write functions. They make your code more reliable, easier to debug, and make you think critically about how you are handling data. A good resource to start learning about writing functions is [How to Write a Function in R](https://www.earthdatascience.org/courses/earth-analytics/automate-science-workflows/write-function-r-programming/).
:::

## Singular elements

You can think of singular elements as the contents of a single cell in a data frame. In the bookstore example, you could arrange each book as a row and each child node as a column.

```{r}
bookstore_xml_text = '<bookstore>
  <book category="children">
    <title>Harry Potter</title>
    <author>J K. Rowling</author>
    <year>2005</year>
    <price>29.99</price>
  </book>
  <book category="web">
    <title>Learning XML</title>
    <author>Erik T. Ray</author>
    <year>2003</year>
    <price>39.95</price>
  </book>
</bookstore>'

bookstore_xml_parsed = xmlParse(bookstore_xml_text)

(bookstore_xml_df = xmlToDataFrame(bookstore_xml_parsed))
```

In cases where your data are entirely singular nodes, you can convert XML to a dataframe using two functions from `{XML}`[^8]: `xmlParse()` and `xmlToDataFrame()`. Because the congressional data has singular and nested element structures, the nested data in fields like `committees`, `actions`, and `sponsors` are combined into single columns. If your data is not all singular nodes like this, you'll need to do a little bit more work to get the data into a [tidy data](https://vita.had.co.nz/papers/tidy-data.html) frame.

[^8]: When you're working with both the `{XML}` and `{xml2}` libraries, it is important to note that their functions often rely on different object types. In the case of `xmlToDataFrame()`, it does not take `{xml_document}` or `{xml_node}` objects. If you try to use them, you'll see an error like this:

    ```{r}
    #| label: xml-df-error
    #| error: true

    xmlToDataFrame(bill_xml)
    ```

```{r}
#| label: xml-to-df
#| class-output: code-block-h

# First you need to use the xmlParse function
bill_xml_parse = xmlParse(bill_xml)

xmlToDataFrame(getNodeSet(bill_xml_parse, "//bill")) %>% 
  glimpse()
```

::: callout-note
## Note

In this example, we actually need to use `getNodeSet(., [path =] "//bill")` to select only nodes in `<bill>`. If we just passed `bill_xml_parse`, we would get a dataframe with two rows because the top-level nodes are bill and the metadata identifier node `<dublinCore>`.
:::

To start building our congressional bill dataset, we need to isolate singular elements like `billNumber` and `billType` by selecting nodes which meet two criteria: 1) the node does not have any child nodes of its own, and 2) the node is not an empty string. I use to extract nodes based on an [XPath](https://www.w3schools.com/xml/xml_parser.asp) (XML Path Language) string. It returns an `{xml_nodeset}` which is then coerced to a list using `as_list()`.

As the help file for `xml_find_all()` says, "XPath is like regular expressions for trees". The expression selects the nodes which match the given path or pattern[^9]. In the code below `//bill/*` selects the child nodes in a bill. The expressions `[` within the square brackets `]` are called predicates which I use to find nodes which have no children with the XPath `count` function and nodes which are not empty strings[^10].

[^9]: [A very useful table of XPath syntax](https://www.w3schools.com/XML/xpath_syntax.asp){target="_blank"}

[^10]: In the process of writing this, I discovered that using XPath made this \~5x faster than an equivalent function in R.

    ```{r}
    #| label: singular-nodes
    #| code-fold: show
    # Function to select singular child nodes from XML node
    xml_singular_nodes = function(xml_node){
      # Return child nodes of current node
      child_nodes = xml_children(xml_node)
      # Select child nodes with 0 children
      zero_length_child_nodes = child_nodes[xml_length(child_nodes) == 0]
      
      # Keep the nodes which are not empty strings
      keep(zero_length_child_nodes, ~(xml_text(.) != ""))
    }

    ```

    ```{r}
    #| label: bench-node-selection

    # Using XPath:
    # singular_nodes1 = xml_find_all(bill_xml, 
    #                                 "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")

    # Using R function:
    # singular_nodes2 = xml_singular_nodes(bill_node)

    # Check they are the same
    # all.equal(singular_nodes1, singular_nodes2)

    # benchmark the two different ways of selecting nodes
    microbenchmark::microbenchmark(
      xml_singular_nodes = xml_singular_nodes(bill_node),
      xml_find_all = xml_find_all(bill_xml, "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]")
    )
    ```

```{r}
#| label: singular-nodes-list
#| code-fold: show

singular_nodes = xml_find_all(
  bill_xml, 
  "//bill/*[count(./*) = 0 and not(string-length(.) = 0)]"
  )

(singular_list = as_list(singular_nodes)) %>% 
  glimpse()
```

Note that we didn't retain the element names so we need to assign them ourselves. When your data is in a named list, you can flatten each element in the list into a **d**ata **f**rame **c**olumn using purrr's `flatten_dfc()` .

```{r}
#| label: singular-nodes-list-named
#| code-fold: show
singular_list_named = setNames(singular_list, 
                                xml_name(singular_nodes))

(bill_df = flatten_dfc(singular_list_named)) %>% 
  glimpse()
```

```{r}
#| label: singular-nodes-rt
#| column: page
#| echo: false
#| eval: false
reactable(bill_df,
          theme = moke_rt(),
            columns = list(
              "constitutionalAuthorityStatementText" = colDef(show=F),
              "createDate" = colDef(format = colFormat(date = T), width = 100),
              "updateDate" = colDef(format = colFormat(date = T), width = 100),
              "introducedDate" = colDef(format = colFormat(date = T), width = 120),
              "congress" = colDef(width = 90),
              "originChamber" = colDef(show=F),
              "version" = colDef(show=F, width = 80),
              "billNumber" = colDef(width = 105),
              "billType" = colDef(width = 85),
              "title" = colDef(minWidth = 180)
            ))
```

## Nested elements

At this point I should be clear about one of my assumptions: that performance with list-columns scales reasonably in various dimensions. I have yet to hit a computational wall[^11], but I am sure at some point it would be much smarter to store this information in a relational database. In either case you may come across elements with multiple children, multiple children with their own sub-elements, and elements with nested XML data. I'll be As you dive deeper into your data you'll likely have to decide which information you're extracting and how.

[^11]: Parsing \~12,000 congressional bills takes 20 minutes for my computer.

To include actions and votes, we can take advantage of the `nest()`/`unnest()` functionality of `{tidyr}`. We use the same steps as before to convert the XML to a list and then nest them in a list column.

### Multiple children

This section's still under construction, if you're reading this and you're not someone I sent this to I am impressed you've managed to reach this corner of the internet.

### Multiple children with sub-elements

The actions node has an `<item>` child node for each congressional action taken for a bill, such as being introduced, sent to a committee, debated on the floor, etc.. Just as before, we use `as_list()` to convert the `{xml_nodeset}` to a list.

```{r}
#| label: actions-list
#| code-fold: show

actions_xml = xml_find_all(bill_node, "actions/item")

actions_list = as_list(actions_xml)

# Look at first action
glimpse(actions_list[[1]])
```

In the individual action container, we have the date, a list of committees related to the action, some administrative information, the text and type of action. To deal with this, we can write a function (or set of functions) like the ones below to process an action.

```{r}
#| label: actions-functions
#| code-fold: true
#| code-summary: "View Functions"
# Helper function: flatten_dfc_rename
# flatten a list to data frame and 
# rename the columns with a given prefix
flatten_dfc_rename = function(list_to_flatten, 
                          name_prefix = "prefix"){
  rename_with(
    .data = flatten_dfc(list_to_flatten), 
    .fn = ~str_c(name_prefix, "_", .),
    # Exclude columns which already start with the prefix
    .cols = -starts_with(name_prefix)
    )
}

# Function: parse_action
# Parse actions from list to data frame
parse_action = function(action){
  action %>% 
    # Flatten+rename sourceSystem elements
    map_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten+rename committees
    map_at("committees", function(committee){
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    # Lastly, clean the names
    janitor::clean_names()
}

```

```{r}
#| label: benchmark-parse-action
#| eval: false
#| include: false
# Test modify_at vs map_at
parse_action2 = function(action){
  action %>% 
    # Flatten+rename  sourceSystem elements
    modify_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    # Flatten+rename committees
    modify_at("committees", function(committee){
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    # Flatten object to data frame
    flatten_dfc_rename(., "action") %>% 
    janitor::clean_names()
}

# Parse the first action
parse_action2(actions_list[[1]])

# What about speed?
microbenchmark::microbenchmark(
  parse_action = parse_action(actions_list[[1]]),
  parse_action2 = parse_action2(actions_list[[1]]), times = 1000
)
```

Using the `{purrr}` library's `map_dfr()`, we apply this function to each action and combine the results into **d**ata **f**rame **r**ows. Here's the output of this process:

```{r}
# Parse the first action
(actions_df = map_dfr(actions_list, parse_action)) %>% 
  glimpse()
```

It is useful to be explicit about the data types when you plan to combine rows into a data frame or `unnest()` the data in the future. I do this using `type_convert()` to ensure the columns have a specific datatype. To add these actions data as a list column to `bill_df` we can simply use dollar assignment.

```{r}
#| label: actions-dfr
#| code-fold: show

actions_df = type_convert(actions_df,
                          col_types = cols(
                            action_date = col_date(), 
                            action_time = col_time(),
                            action_committee_systemCode = col_character(), 
                            action_committee_name = col_character(), 
                            action_source_code = col_character(),
                            action_source_name = col_character(),
                            action_text = col_character(), 
                            action_type = col_character(), 
                            action_code = col_character()
                            )
                          )

bill_df$actions = list(actions_df)
```

```{r}
#| eval: false
#| include: false
#| echo: false

bill_actions = xml_find_all(actions_node, "item")
    
bill_action_counts = as_list(xml_find_all(actions_node, "./*[not(self::item)]")) %>%
  map_dfc(flatten_dfc) %>% 
  rename_with(.cols = everything(), ~str_c("actions_", .)) %>% 
  pivot_longer(everything(), names_to = "action", names_prefix = "actions_", values_to = "count")

# Coerce nodes to list
actions_df = as_list(bill_actions) %>% 
  map_dfr(parse_action) %>% 
  type_convert(col_types = col_specs$actions)

bill_df$actions = list(actions_df)

bill_df$action_counts = list(type_convert(bill_action_counts,
                                          col_types = cols(action = col_character(), count = col_integer())))
```

### Nested XML

Sometimes you can even have links to other XML files in a node, as we can see in the `<recordedVotes>` element. Votes are particularly interesting because it provides a more discrete measure of our representatives' behaviour.

```{r}
#| label: vote-nodes-contents
(bill_recorded_vote_nodes = xml_find_all(bill_node, "recordedVotes/recordedVote"))
```

You may have spotted why votes are interesting elements to parse because inside the `<url>` element we find **another** **XML file**![^12] Before we dive into that can of worms, I'll convert the top-level nodes to a list and flatten it into columns. Note we use `map_dfr()` with `votes_list` because there could be multiple vote objects.

[^12]: ![They heard you like XML so they put XML in your XML](https://c.tenor.com/um2EhyMQyR8AAAAC/xzibit-meme.gif){width="267"}

```{r}
#| label: vote-nodes-df
# Coerce nodes to list
recorded_votes_list = as_list(bill_recorded_vote_nodes)

(recorded_votes_df = map_dfr(recorded_votes_list, flatten_dfc)) %>% 
  glimpse()
```

Now we want to get the vote roll XML file, so we go back to `read_xml()` . There are two main nodes - `<vote-metadata>` and `<vote-data>`. One node contains the aggregated vote information, while `<vote-data>` contains the legislator-level vote data. Let's try to parse the legislator-level data first. Here is the XML for a single legislator's vote:

```{r}
#| label: vote-roll-xml
vote_roll_xml = read_xml(recorded_votes_df$url)

vote_data = xml_find_all(vote_roll_xml, "vote-data")

vote_legislators = vote_data %>% 
  xml_find_all("recorded-vote")

(legislators_list = as_list(vote_legislators))[1] %>% 
  glimpse()

```

With a similar combination of `as_list()` , `flatten_dfr()`, and `unnest()` we can flatten the XML into one row per legislator but we lose all the attributes.

```{r}
#| label: vote-roll-data-flat
(vote_roll_flattened = vote_data %>% 
  as_list() %>% 
  flatten_dfr() %>% 
    unnest(everything()))
```

Instead we'll need to extract the attributes before we flatten the data. We want to extract the attributes only for legislator using `map()` to apply `map_at()` on each legislator element and extract the attributes from each while retaining the value in `vote`. It can often feel like you're getting lost in a list of lists, but with some experimentation you'll be able to find your way back to the surface.

```{r}
#| label: vote-roll-leg-df
(legislator_vote_df = legislators_list %>% 
    # Modify one level deeper using map_at to target legislator elements
    map(map_at, "legislator", attributes) %>% 
    map_dfr(flatten_dfc))
```

Now we have a table of legislator voting data! But what about the `<vote-metadata>`? Everything other than the `<vote-totals>` element is singular so we can get that out of the way the same way as before:

```{r}
#| label: vote-roll-metadata-xml
vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")

vote_singular_nodes = xml_singular_nodes(vote_metadata)

(vote_df = as_list(vote_singular_nodes) %>% 
  # as_list() doesn't retain element names so we set names ourselves
  setNames(xml_name(vote_singular_nodes)) %>% 
  flatten_dfc()) %>% 
  glimpse()
```

The `<vote-totals>` are a bit of a unique little element, with 3 different types of nodes. This is another opportunity for us to be choosy with our data. The first node is table headers, which we don't need because the elements are tagged anyway. From these, we really only need the `<totals-by-party>` nodes as long as the totals of which agree with `<totals-by-vote>` , which is worth checking.

```{r}
#| label: vote-roll-metadata-totals-contents
#| layout-nrow: 1
(vote_totals = xml_find_all(vote_metadata, "vote-totals")) %>% 
  xml_contents()

vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")

party_vote_totals_df = as_list(vote_totals_by_party) %>% 
  map_dfr(flatten_dfc) %>% 
    type_convert()

(totals_by_vote = xml_find_all(vote_totals, "totals-by-vote")) %>% 
  xml_contents()
```

Once we have our nodeset (which at last are all singular), we use same listing, mapping, and flattening...or *lappening* as absolutely no one calls it.

```{r}
#| eval: false
#| include: false
# Check if totals match
as_list(totals_by_vote) %>% 
  map_dfr(flatten_dfc)

summarise(party_vote_totals, 
          across(.cols = -party, sum, na.rm=T))
# They do!
```

Now that we have all of our vote data wrangled from the thorny grasp of XML, we can put it all together.

```{r}
#| label: vote-roll-build
vote_roll_df = vote_df %>% 
  mutate(legislator_votes = list(legislator_vote_df),
         party_votes = list(party_vote_totals_df)) %>% 
    janitor::clean_names()

(recorded_votes_df = recorded_votes_df %>% 
  mutate(vote_roll = list(vote_roll_df))) %>% 
  glimpse()

bill_df$votes = list(recorded_votes_df)
```

...all the way until we've gotten back to the bill-level. Now we have the bill-level characteristics with action and vote information nested in list columns. If we want to analyze the actions data, we simply have to `unnest()` it.

```{r}
#| label: unnest-actions
unnest(bill_df, actions) %>% 
  glimpse()
```

I'll stop there for brevity's sake, but you can find the code for extracting the full XML file [here](https://github.com/MokeEire/my-reps/blob/master/R/parsing_functions.R)[^13].

[^13]: Ctrl/Cmd+F: `extract_bill_status`

# TL;DR: Main Points

Processing XML documents can be simple depending on their structure, so try the simplest method if you can. If your data is making use of XML's flexibility you might but it can be boiled down to these steps:

1.  **Explore the structure**

> Go through any available documentation, and when you read in the XML file you can use functions like `xmlParse()`, `xml_structure()`, and `xml_contents()` .

2.  **Define the output**

> Consider what you want the output to look like and think about how it needs to be transformed to match this target.

3.  **Process a single element** (write a function if it gets too complicated)

> Get one element into the form you want. Writing functions can help you think through the data transformations being applied and make your code easier to read.

4.  **Apply to all elements**

> Focus on processing of the entire file (or the subset of the file you're interested in). You might want an XML file to return a single row, a single column, or a data frame of size $n\times k$. Once you have a single file returned in the format you want, you can combine the outputs of multiple files.

Please reach out with any questions or feedback! All is welcome, and there may even be a reward for anyone who finds a mistake in the code.

```{r}
#| eval: false
#| include: false
parse_vote_roll = function(vote, logger, bill_type, bill_num){
  
  tryCatch(
    {
      vote_xml = read_xml(vote, options = "RECOVER")
      vote_data = xml_find_all(vote_xml, "vote-data")
      
      vote_roll_children = xml_children(vote_roll_xml)
      vote_data = xml_find_all(vote_roll_xml, "vote-data")
      
      # Vote data
      vote_legislators = vote_data %>% 
        xml_find_all("recorded-vote")
      legislators_list = as_list(vote_legislators)
      legislator_vote_df = legislators_list %>% 
        # Modify one level deeper using map_at to target legislator elements
        map(map_at, "legislator", attributes) %>% 
        map_dfr(flatten_dfc)
      
      # Vote metadata
      vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")
      vote_singular_nodes = xml_singular_nodes(vote_metadata)
      (vote_df = as_list(vote_singular_nodes) %>% 
          # as_list() doesn't retain element names so we set names ourselves
          setNames(xml_name(vote_singular_nodes)) %>% 
          flatten_dfc())
      
      # Vote totals
      vote_totals = xml_find_all(vote_metadata, "vote-totals")
      vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")
      party_vote_totals_df = vote_totals_by_party %>% 
        as_list() %>% 
        map_dfr(flatten_dfc) %>% 
        type_convert()
      
      vote_roll_df = vote_df %>% 
        mutate(legislator_votes = list(legislator_vote_df),
               party_votes = list(party_vote_totals_df)) %>% 
        janitor::clean_names()
      
      vote_list = as_list(vote_data)
      
      flatten_dfr(vote_list) %>% 
        unnest(everything())
    },
    error=function(cond) {
      log_info(logger, 
               bill_type = bill_type,
               bill_num = bill_num, 
               "ERROR: Vote roll could not be parsed")
      # Choose a return value in case of error
      return(tibble())
    }
  )
  
  
}
```

# Other helpful articles

Here are some of the helpful articles I came across in the course of writing this:

-   [From XML to Excel for Data Analysis](https://towardsdatascience.com/from-xml-to-excel-for-data-analysis-ac0c0c765b7d "Introduction to Processing XML In Python")
-   [Reading XML files in R](https://medium.com/geekculture/reading-xml-files-in-r-3122c3a2a8d9)

# Session Info

Version information about R, OS, and loaded packages.

```{r}
#| label: session-info
#| echo: false
sessioninfo::session_info("loaded")
```
