---
title: "Parsing XML with R, using congressional legislative data"
author: "Mark"
---

```{r}
#| label: setup
#| message: false
library(extrafont)
library(reactable)

source("https://github.com/MokeEire/my-reps/raw/master/R/parsing_functions.R")
bill_xml_link = "https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml"
bill_xml_file = read_xml(bill_xml_link)
```

```{r}
#| label: df-print-fct
#| include: false

knit_print.data.frame = function(x, ...){
  knitr::knit_print(
    reactable(x,
              compact = T, 
              resizable = T,
              ),
    ...
    )
}
```

If you work with data regularly, you have probably used a plethora of data input formats, from Excel spreadsheets and text files to relational databases and potentially XML. (e)Xtensible Markup Language is a storage type designed for flexibly storing and transmitting data[^1]. This flexibility often leads to a bit of a hassle when trying to parse XML data. If you're still reading, the good news is that this article should provide an understanding of XML and a set of steps for processing an XML file with R into a more analysis-friendly format.

[^1]: [Wikipedia](https://en.wikipedia.org/wiki/XML) for the curious. Don't miss the drama about Microsoft's "vociferous protests" as one of the co-editors started working with Netscape.

::: {.callout-tip appearance="simple"}
## In this post you will learn to:

-   Load and parse XML files in R using the [`{xml2}`](https://xml2.r-lib.org/) package

-   Explore the structure of XML documents
:::

In this post I'll be using the US government's congressional bill data. The first step of data analysis is always to check the documentation[^2] and thankfully [govinfo](https://www.govinfo.gov/) has provided some [documentation to guide us](https://github.com/usgpo/bill-status/blob/main/BILLSTATUS-XML_User_User-Guide.md).

[^2]: Sorry to all whose documentation is:\
    "We don't have anything like that, but you can ask \[Impossibly busy data engineer\], they know everything you need."

To follow along, you can download the sample XML file [here](https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml "HR-391: Global Health Security Act of 2021"), while you can find the bulk data [here](https://www.govinfo.gov/bulkdata/BILLSTATUS). The sample file (chosen because it contains a variety of important elements) contains information about HR-391: Global Health Security Act of 2021 including its sponsors and cosponsors, votes on the bill, and the committees that considered it. Here's a sample of the XML:

```{r}
#| code-overflow: scroll
#| echo: false
(example_node = xml_find_first(bill_xml_file, "//bill/recordedVotes")) %>% 
  xmlParse()

```

Above is an example of how votes recorded on the bill are stored. The `<recordedVotes>` container can have multiple `<recordedVote>` elements which describe a vote taken on the bill[^3].

[^3]: We can (and later I do) go deeper here and extract the roll's XML file to get individual representatives' votes.

# Read XML data with R

We'll load the {XML} and {xml2} packages to read in our XML file. Between these two libraries there are numerous ways to load in and process XML data. I strongly suggest looking through the packages' help files to find the right function for your task. I also load the {tidyverse} package because it's generally exceedingly useful.

```{r}
#| code-fold: show
library(tidyverse)
library(XML)
library(xml2)

bill_xml_file = read_xml("https://www.govinfo.gov/bulkdata/BILLSTATUS/117/hr/BILLSTATUS-117hr391.xml")
```

`read_xml()` returns an `xml_document`[^4] object. With this, we can look at the bill's top level nodes.

[^4]: `xml_document` is one of the "key classes" used in the `{xml2}` library, the others being `xml_node` (a single node), and `xml_nodeset` (a set of nodes).

```{r}
#| code-fold: show
# Look at the contents
xml_contents(bill_xml_file)
```

In this case it's actually more useful to look at the `<bill>` element which is a child node of our XML document[^5], which is what `xml_child()` is for.

[^5]: I will confess I'm not quite sure why this is the case, nor do I particularly understand what `<dublinCore>` is (though prevailing theories suggest some kind of document schema or a new metal genre originating from my home of Dublin).

```{r}
#| code-fold: show
#| label: xml-bill-child
#| code-overflow: wrap
# Return child nodes named bill
(bill_xml = xml_child(bill_xml_file, "bill"))
```

Parsing this file to a dataframe will require a little thought because we have a number of nodes which have multiple data points within them. However it's always a good idea to try the simplest approach first, which is the aptly named `xmlToDataFrame()`.

```{r}
#| label: xml-to-df
#| code-fold: show
# First you need to use the xmlParse function
bill_xml_parse = xmlParse(bill_xml_file)

# You can wrap a variable assignment in ( ) to print it, 
# or in this case pass it to another function via the pipe %>% 
( bill_xml_df_attempt = xmlToDataFrame(getNodeSet(bill_xml_parse, "//bill")) ) %>% 
  # View the dataframe structure
  glimpse()
```

But you might notice that a number of fields like `actions`, `committees`, and `sponsors` have had their values concatenated. This approach may work for simpler XML structures, but in this case we need to do a little bit more work which brings us to one of the cardinal rules of data analysis:

::: {.callout-tip appearance="simple"}
## Look at your data

Look at the structure and contents of your data and understand how it is organized. This is essential for coming up with a solution to consistently process the data.
:::

# Define the output

Another important step is to think about the form we want the data so we can determine how to transform it. I want the congressional data to have one row per bill, with the nested characteristics stored in list columns. This will produce a comprehensive dataset which can easily be subset and transformed to various levels of observation as needed. The end result looks like this:

```{r}
#| echo: false
#| message: false
#| column: screen-inset-shaded
example_bill_df = extract_bill_status(bill_xml_link, log_types = NULL)

example_bill_df %>% # glimpse() # here to check the data
  select(
    -bill_id, -where(is_list) # remove list columns?
  ) %>%
  reactable::reactable(
    theme = moke_rt(),
    compact = T,
    resizable = T,
    wrap = F,
    columns = list(
      "latest_action_action_date" = colDef(name = "action_date", 
                                           format = colFormat(date = T)),
     "latest_action_text" = colDef(name = "action_text"),
       "constitutional_authority_statement_text" = colDef(show=F),
      "create_date" = colDef(format = colFormat(date = T), width = 95),
      "update_date" = colDef(format = colFormat(date = T), width = 95),
      "introduced_date" = colDef(format = colFormat(date = T), width = 130),
      "congress" = colDef(width = 80),
      "version" = colDef(width = 80),
      "bill_number" = colDef(width = 100),
      "bill_type" = colDef(width = 80),
      "title" = colDef(minWidth = 180)
    ), 
    columnGroups = list(
      colGroup(name = "Latest Action",
                            columns = c("latest_action_action_date",
                                        "latest_action_text"))
    )
  )
```

With the following list columns:

::: panel-tabset
## Committees

```{r}
#| echo: false
glimpse(example_bill_df[["committees"]])

```

## Votes

```{r}
#| echo: false
glimpse(example_bill_df[["votes"]])

```

## Actions

```{r}
#| echo: false
glimpse(example_bill_df[["actions"]])
```

## Sponsors

```{r}
#| echo: false
glimpse(example_bill_df[["sponsors"]])
```

## Cosponsors

```{r}
#| echo: false
glimpse(example_bill_df[["cosponsors"]])
```

## Summaries

```{r}
#| echo: false
glimpse(example_bill_df[["bill_summaries"]])
```

## Versions

```{r}
#| echo: false
glimpse(example_bill_df[["bill_text_versions"]])
```
:::

With this output in mind and an understanding of the current data structure, we can break the process down into two broad categories - the simple, and the not-so-simple.

# Parsing

## Parse the simple elements

The simple parts of the data to process are those which are already at the level of observation you want. In our case - at the bill level. These are typically the top-level nodes which only have one piece of data. To select only these nodes we can write a function like the one below:

```{r}
#| label: singular-nodes
#| code-fold: show
# Function to select singular child nodes from XML node
xml_singular_nodes = function(xml_node){
  # Return child nodes of current node
  child_nodes = xml_children(xml_node)
  # Select child nodes with 0 children
  zero_length_child_nodes = child_nodes[xml_length(child_nodes) == 0]
  
  # Keep the nodes which are not empty strings
  keep(zero_length_child_nodes, ~(xml_text(.) != ""))
}

(singular_nodes = xml_singular_nodes(bill_xml))

```

Now with a nifty combination of `as_list()`, `xml_name()`, and `flatten_dfc()` we can convert the singular nodes into a single row of data.

```{r}
#| label: singular-nodes-df
#| code-fold: show
bill_df = as_list(singular_nodes) %>% 
  # as_list() doesn't retain element names so we set names ourselves
  setNames(xml_name(singular_nodes)) %>% 
  flatten_dfc()
```

Which gives us a single row of data:

```{r}
#| label: singular-nodes-rt
#| column: page
#| echo: false
reactable(bill_df,
          theme = moke_rt(),
            columns = list(
              "constitutionalAuthorityStatementText" = colDef(show=F),
              "createDate" = colDef(format = colFormat(date = T), width = 90),
              "updateDate" = colDef(format = colFormat(date = T), width = 90),
              "introducedDate" = colDef(format = colFormat(date = T), width = 120),
              "congress" = colDef(width = 80),
              "version" = colDef(width = 80),
              "billNumber" = colDef(width = 100),
              "billType" = colDef(width = 80),
              "title" = colDef(minWidth = 180)
            ))
```

::: callout-caution
## \`flatten_dfc()\` drops empty elements

Note that `flatten_dfc()` drops list elements which are empty (possibly through `compact()`?). This means our output varies based on each file's contents. This is not an issue itself, but it is something to be wary of if you plan on combining multiple XML files.
:::

Now we have the bill title, when it was introduced, what type of bill it is, and which congress introduced it. I also want to include the data for actions, sponsors, committees, and votes, but these need to processed individually.

## Parse the not-so-simple elements

This is where the majority of the legwork is so if you can comfortably ignore[^6] some portion of the data, now's a good time. There's no point spending an hour trying to write a function for one particularly difficult bit of information only to realize you don't need it anyway.

[^6]: But do yourself a favour and write it down somewhere - comment it in the code, tell your colleagues or collaborators, put it on a particularly strong post it, whatever works.

For brevity I will just go through actions and votes, but you can find the code for extracting the full XML file [here](https://github.com/MokeEire/my-reps/blob/master/R/parsing_functions.R) (Ctrl/Cmd+F: `extract_bill_status`)

### Actions

```{r}
#| label: actions-xml
(actions_xml = xml_find_all(bill_xml, "actions/item"))
```

So this bill has 14 actions recorded on it. We can use `as_list()` to convert the XML to a list.

```{r}
#| label: actions-list
#| code-fold: show
actions_list = as_list(actions_xml)

glimpse(actions_list[[1]])
```

In the individual action container, we can see we have the type, text, and date of the action, a list of committees related to the action, and some elements which are singular and some which are not. To deal with this, we can write a function (or set of functions) like the ones below to process an action:

```{r}
#| label: actions-functions
#| code-fold: show
# Function to flatten a list to dataframe columns and 
# rename the columns with a given prefix
flatten_dfc_rename = function(list_to_flatten, 
                          name_prefix = "prefix"){
  rename_with(flatten_dfc(list_to_flatten), ~str_c(name_prefix, "_", .))
}

# Parse actions from list to dataframe
parse_action = function(action){
  action %>% 
    # Flatten sourceSystem elements and rename them
    modify_at("sourceSystem", ~flatten_dfc_rename(.x, "source")) %>% 
    modify_at("committees", function(committee){
      map_dfr(committee, ~flatten_dfc_rename(.x, "committee"))
    }) %>% 
    flatten_dfc() %>% 
    rename_with(.fn = ~str_c("action_", .), .cols = -starts_with("action")) %>% 
    janitor::clean_names()
}

parse_action(actions_list[[1]])
```

Using `{purrr}`'s `map_*()` functions, we can apply this function over all of the items:

```{r}
#| label: actions-dfr
#| code-fold: show
(actions_df = map_dfr(actions_list, parse_action)) %>% 
  glimpse()
```

Now if you're processing a large amount of these data, you may want to be explicit about the data types expected in each column. This is vital when we want to `unnest()` the actions data and combine many bills' actions into an actions-level dataset. You can do this using `type_convert()` , notice the change in column types from the output above.

```{r}
#| label: actions-type-conv
(actions_df = type_convert(actions_df,
                          col_types = cols(
                            action_date = col_date(), 
                            action_time = col_time(),
                            action_committee_systemCode = col_character(), 
                            action_committee_name = col_character(), 
                            action_source_code = col_character(),
                            action_source_name = col_character(),
                            action_text = col_character(), 
                            action_type = col_character(), 
                            action_code = col_character()
                            )
                          )) %>% 
  glimpse()
```

To add these actions data as a list column to `bill_df` we can simply use dollar assignment.

```{r}
#| label: add-actions
#| code-fold: show
bill_df$actions = list(actions_df)

glimpse(bill_df)
```

The remaining sections will be following the same process for different elements, but it can be boiled down to these steps:

1.  **Explore the structure**

> Go through any available documentation, and when you read in the XML file you can use functions like `xmlParse()`, `xml_structure()`, and `xml_contents()` .

2.  **Define the output**

> Consider what you want the output to look like and think about how it needs to be transformed to match this target.

3.  **Process a single element** (write a function if it gets too complicated)

> Get one element into the form you want. Writing functions can help you think through the data transformations being applied and make your code easier to read.

4.  **Apply to all elements**

> Focus on processing of the entire file (or the subset of the file you're interested in). You might want an XML file to return a single row, a single column, or a dataframe of size $n\times k$. Once you have a single file returned in the format you want, you can combine the outputs of multiple files.

::: {.callout-caution appearance="simple"}
## Find the exceptions

Lastly, you will likely run into situations where a node which only seemed to contain a single piece of data has a different structure with multiple sub-elements for other files. This will happen, you'll go back to the drawing board, design more flexibility in your functions, and understand how process either format.
:::

```{r}
#| eval: false
#| include: false
#| echo: false

bill_actions = xml_find_all(actions_node, "item")
    
bill_action_counts = as_list(xml_find_all(actions_node, "./*[not(self::item)]")) %>%
  map_dfc(flatten_dfc) %>% 
  rename_with(.cols = everything(), ~str_c("actions_", .)) %>% 
  pivot_longer(everything(), names_to = "action", names_prefix = "actions_", values_to = "count")

# Coerce nodes to list
actions_df = as_list(bill_actions) %>% 
  map_dfr(parse_action) %>% 
  type_convert(col_types = col_specs$actions)

bill_df$actions = list(actions_df)

bill_df$action_counts = list(type_convert(bill_action_counts,
                                          col_types = cols(action = col_character(), count = col_integer())))
```

### Votes

Votes are particularly interesting because it provides a more discrete measure of our representatives' behaviour. They are also an interesting element to parse because we need to use the `<url>` element to parse an individual vote roll XML file.

```{r}
bill_recorded_votes = xml_find_all(bill_xml, "recordedVotes")

(bill_recorded_vote_nodes = xml_find_all(bill_recorded_votes, "recordedVote")) %>% 
  xml_contents()
```

Because the data structure is all top-level nodes, we can simply convert it to a list and flatten it into columns. Note we use `map_dfr()` with `votes_list` because there could be multiple vote objects.

```{r}
# Coerce nodes to list
recorded_votes_list = as_list(bill_recorded_vote_nodes)

(recorded_votes_df = map_dfr(recorded_votes_list, flatten_dfc)) %>% 
  glimpse()
```

Now we want to get the vote roll XML file, so we go back @sec1 and use `read_xml()`

```{r}
(vote_roll_xml = read_xml(recorded_votes_df$url))
```

There are two main nodes - `<rollcall-vote>` and `<vote-data>`. What does the structure for these nodes look like?

```{r}
vote_roll_children = xml_children(vote_roll_xml)
xml_length(vote_roll_children)
```

```{r}
vote_roll_children
```

```{r}
#| layout-nrow: 1
map(vote_roll_children, xml_contents)
```

One node contains the aggregated vote information, while `<vote-data>` contains the legislator-level vote data. Let's try to parse the legislator-level data first.

```{r}
(vote_data = xml_find_all(vote_roll_xml, "vote-data"))
```

Here is the XML for a single legislator's vote:

```{r}
xml_child(vote_data)
```

With a similar combination of `as_list()` , `flatten_dfr()`, and `unnest()` we can flatten the XML into one row per legislator

```{r}
(vote_roll_flattened = vote_data %>% 
  as_list() %>% 
  flatten_dfr() %>% 
    unnest(everything()))
```

But we lose all the attributes! And `name-id` looked particularly useful. We'll need to extract the attributes before we flatten the data. Let's take another look at the legislators structure.

```{r}
vote_legislators = vote_data %>% 
  xml_find_all("recorded-vote")

(legislators_list = as_list(vote_legislators))[1] %>% 
  glimpse()
```

The legislator element has all the attributes, while the vote element only has a value. We want to extract the attributes only for legislator using `map()` to apply `map_at()` on each legislator element and extract the attributes from each while retaining the value in `vote`. It can often feel like you're getting lost in a list of lists, but with some experimentation you'll be able to find your way back to the surface.

```{r}
(legislator_vote_df = legislators_list %>% 
    # Modify one level deeper using map_at to target legislator elements
    map(map_at, "legislator", attributes) %>% 
    map_dfr(flatten_dfc))
```

Now we have a table of legislator voting data! But what about the `<vote-metadata>`?

```{r}
(vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")) %>% 
  xml_contents()
```

Everything other than the `<vote-totals>` element is singular so we can get that out of the way the same way as before:

```{r}
vote_singular_nodes = xml_singular_nodes(vote_metadata)

(vote_df = as_list(vote_singular_nodes) %>% 
  # as_list() doesn't retain element names so we set names ourselves
  setNames(xml_name(vote_singular_nodes)) %>% 
  flatten_dfc()) %>% 
  glimpse()

```

The `<vote-totals>` are a bit of a unique little element, with 3 different types of nodes.

```{r}
(vote_totals = xml_find_all(vote_metadata, "vote-totals")) %>% 
  xml_contents()
```

This is another opportunity for us to be choosy with our data. The first node is table headers, which we don't need because the elements are tagged anyway. From these, we really only need the `<totals-by-party>` nodes as long as the totals of which agree with `<totals-by-vote>` , which is worth checking.

```{r}
#| layout-nrow: 1
(vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party"))

(totals_by_vote = xml_find_all(vote_totals, "totals-by-vote")) %>% 
  xml_contents()
```

Once we have our nodeset (which at last are all singular), we use same listing, mapping, and flattening...or *lappening* as absolutely no one calls it.

```{r}
#| message: false
#| warning: false
(party_vote_totals_df = vote_totals_by_party %>% 
  as_list() %>% 
  map_dfr(flatten_dfc) %>% 
    type_convert())
```

```{r}
#| eval: false
#| include: false
# Check if totals match
as_list(totals_by_vote) %>% 
  map_dfr(flatten_dfc)

summarise(party_vote_totals, 
          across(.cols = -party, sum, na.rm=T))
# They do!
```

Now that we have all of our vote data wrangled from the thorny grasp of XML, we can put it all together.

```{r}
(vote_roll_df = vote_df %>% 
  mutate(legislator_votes = list(legislator_vote_df),
         party_votes = list(party_vote_totals_df)) %>% 
    janitor::clean_names()) %>% 
  glimpse()
```

And we continue to stack this Russian doll of data from the legislator-level to the vote-level...

```{r}
(recorded_votes_df = recorded_votes_df %>% 
  mutate(vote_roll = list(vote_roll_df))) %>% 
  glimpse()
```

...all the way until we've gotten back to the bill-level.

```{r}
bill_df$votes = list(recorded_votes_df)

glimpse(bill_df)
```

```{r}
#| eval: false
#| include: false
parse_vote_roll = function(vote, logger, bill_type, bill_num){
  
  tryCatch(
    {
      vote_xml = read_xml(vote, options = "RECOVER")
      vote_data = xml_find_all(vote_xml, "vote-data")
      
      vote_roll_children = xml_children(vote_roll_xml)
      vote_data = xml_find_all(vote_roll_xml, "vote-data")
      
      # Vote data
      vote_legislators = vote_data %>% 
        xml_find_all("recorded-vote")
      legislators_list = as_list(vote_legislators)
      legislator_vote_df = legislators_list %>% 
        # Modify one level deeper using map_at to target legislator elements
        map(map_at, "legislator", attributes) %>% 
        map_dfr(flatten_dfc)
      
      # Vote metadata
      vote_metadata = xml_find_all(vote_roll_xml, "vote-metadata")
      vote_singular_nodes = xml_singular_nodes(vote_metadata)
      (vote_df = as_list(vote_singular_nodes) %>% 
          # as_list() doesn't retain element names so we set names ourselves
          setNames(xml_name(vote_singular_nodes)) %>% 
          flatten_dfc())
      
      # Vote totals
      vote_totals = xml_find_all(vote_metadata, "vote-totals")
      vote_totals_by_party = xml_find_all(vote_totals, "totals-by-party")
      party_vote_totals_df = vote_totals_by_party %>% 
        as_list() %>% 
        map_dfr(flatten_dfc) %>% 
        type_convert()
      
      vote_roll_df = vote_df %>% 
        mutate(legislator_votes = list(legislator_vote_df),
               party_votes = list(party_vote_totals_df)) %>% 
        janitor::clean_names()
      
      vote_list = as_list(vote_data)
      
      flatten_dfr(vote_list) %>% 
        unnest(everything())
    },
    error=function(cond) {
      log_info(logger, 
               bill_type = bill_type,
               bill_num = bill_num, 
               "ERROR: Vote roll could not be parsed")
      # Choose a return value in case of error
      return(tibble())
    }
  )
  
  
}
```

# Other helpful articles

Here are some of the helpful articles I came across in the course of writing this:

-   [From XML to Excel for Data Analysis](https://towardsdatascience.com/from-xml-to-excel-for-data-analysis-ac0c0c765b7d "Introduction to Processing XML In Python")

# Session Info

Version information about R, OS, and loaded packages.

```{r}
#| label: session-info
#| echo: false
sessioninfo::session_info("loaded")
```
